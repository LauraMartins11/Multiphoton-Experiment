{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import time\n",
    "\n",
    "import mystic\n",
    "from mystic.solvers import DifferentialEvolutionSolver, diffev2\n",
    "from mystic.strategy import Best1Bin\n",
    "from mystic.monitors import Monitor,VerboseMonitor\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from Tomography import *\n",
    "\n",
    "from NestedForLoop import get_iterator\n",
    "from pathlib import Path\n",
    "from scipy.linalg import sqrtm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.optimize import least_squares\n",
    "\n",
    "import fnmatch\n",
    "\n",
    "working_dir=r\"C:\\Users\\LauraMartins\\Documents\\PhD\\Lab\\Code\\Tomographies\"\n",
    "os.chdir(working_dir+'\\ProcessTomoData')\n",
    "\n",
    "filenames = [i for i in glob.glob(\"Bigiteration_0_*\")]\n",
    "filenames.sort(key=os.path.getmtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order and names in the pseudocode\n",
    "# x=(22.5,0) y=(0,-45) z=(0,0) a=(22.5,45) b=(22.5,0) c=(-22.5,-45) d=(-22.5,0) e=(45,0) f=(0,45)\n",
    "# Channels: 1 2 3 4 12 14 23 24\n",
    "\n",
    "## Matching the datafile name with the respective input and measurement basis\n",
    "IBasisList=['z','e','a','y','c','f'] #in order: H=z V=-z D=x L=y A=-x R=-y\n",
    "MBasisList=['x','y','z'] #in order: D L H\n",
    "\n",
    "anglesInput=['(00.00, 00.00)', '(45.00, 00.00)', '(22.50, 45.00)','(00.00, -45.0)', '(-22.5, -45.0)', '(00.00, 45.00)']\n",
    "anglesOutput=['(22.50, 00.00)','(00.00, -45.0)', '(00.00, 00.00)']\n",
    "BasesI=['H', 'V', 'D', 'L', 'A', 'R']\n",
    "BasesO=['D', 'L', 'H']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input state 0: |HxH|\n",
      "Input state 1: |VxV|\n",
      "Input state 2: |DxD|\n",
      "Input state 3: |LxL|\n",
      "Input state 4: |AxA|\n",
      "Input state 5: |RxR|\n",
      "Input:  H (00.00, 00.00) Output:  D (22.50, 00.00) Sum of counts normalized:  0.9885814333900802\n",
      "Input:  H (00.00, 00.00) Output:  L (00.00, -45.0) Sum of counts normalized:  0.9848456730659485\n",
      "Input:  H (00.00, 00.00) Output:  H (00.00, 00.00) Sum of counts normalized:  0.9883036525286982\n",
      "Input:  V (45.00, 00.00) Output:  D (22.50, 00.00) Sum of counts normalized:  0.9732882161499575\n",
      "Input:  V (45.00, 00.00) Output:  L (00.00, -45.0) Sum of counts normalized:  0.9872494918032443\n",
      "Input:  V (45.00, 00.00) Output:  H (00.00, 00.00) Sum of counts normalized:  0.9876678816045239\n",
      "Input:  D (22.50, 45.00) Output:  D (22.50, 00.00) Sum of counts normalized:  1.0\n",
      "Input:  D (22.50, 45.00) Output:  L (00.00, -45.0) Sum of counts normalized:  0.9922808203396197\n",
      "Input:  D (22.50, 45.00) Output:  H (00.00, 00.00) Sum of counts normalized:  0.9677990364385604\n",
      "Input:  L (00.00, -45.0) Output:  D (22.50, 00.00) Sum of counts normalized:  0.9966394659491165\n",
      "Input:  L (00.00, -45.0) Output:  L (00.00, -45.0) Sum of counts normalized:  0.9797018590670526\n",
      "Input:  L (00.00, -45.0) Output:  H (00.00, 00.00) Sum of counts normalized:  0.9856237364490532\n",
      "Input:  A (-22.5, -45.0) Output:  D (22.50, 00.00) Sum of counts normalized:  0.9873987128195181\n",
      "Input:  A (-22.5, -45.0) Output:  L (00.00, -45.0) Sum of counts normalized:  0.9815461757173906\n",
      "Input:  A (-22.5, -45.0) Output:  H (00.00, 00.00) Sum of counts normalized:  0.9708082965847917\n",
      "Input:  R (00.00, 45.00) Output:  D (22.50, 00.00) Sum of counts normalized:  0.9915517960099418\n",
      "Input:  R (00.00, 45.00) Output:  L (00.00, -45.0) Sum of counts normalized:  0.9704456489139964\n",
      "Input:  R (00.00, 45.00) Output:  H (00.00, 00.00) Sum of counts normalized:  0.9865897478095075\n",
      "State: [[1.+0.j 0.+0.j]]\n",
      "Fast maximum likelihood estimation: \n",
      " [[0.5490974 +4.07366572e-18j 0.45010615+1.96996737e-01j]\n",
      " [0.45010615-1.96996737e-01j 0.4509026 -4.07366572e-18j]] \n",
      "\n",
      "State: [[0.+0.j 1.+0.j]]\n",
      "Fast maximum likelihood estimation: \n",
      " [[ 0.43637926-2.18421159e-17j -0.44437424-2.03628557e-01j]\n",
      " [-0.44437424+2.03628557e-01j  0.56362074+2.18421159e-17j]] \n",
      "\n",
      "State: [[0.70710678+0.j 0.70710678+0.j]]\n",
      "Fast maximum likelihood estimation: \n",
      " [[0.02485664-1.67216968e-18j 0.09288766-8.06286582e-02j]\n",
      " [0.09288766+8.06286582e-02j 0.97514336+1.67216968e-18j]] \n",
      "\n",
      "State: [[0.70710678+0.j         0.        +0.70710678j]]\n",
      "Fast maximum likelihood estimation: \n",
      " [[0.66292207+1.91351435e-17j 0.17975287-4.37201676e-01j]\n",
      " [0.17975287+4.37201676e-01j 0.33707793-1.91351435e-17j]] \n",
      "\n",
      "State: [[ 0.70710678+0.j -0.70710678+0.j]]\n",
      "Fast maximum likelihood estimation: \n",
      " [[ 0.96711176+2.09698646e-18j -0.11500627+8.61949266e-02j]\n",
      " [-0.11500627-8.61949266e-02j  0.03288824-2.09698646e-18j]] \n",
      "\n",
      "State: [[ 0.70710678+0.j         -0.        -0.70710678j]]\n",
      "Fast maximum likelihood estimation: \n",
      " [[ 0.36084365-2.04083262e-17j -0.16498248+4.51016952e-01j]\n",
      " [-0.16498248-4.51016952e-01j  0.63915635+2.04083262e-17j]] \n",
      "\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "ORTHOGONAL STATES OVERLAP V and H: \n",
      " (0.013493286981779151+1.214306433183765e-17j)\n",
      "ORTHOGONAL STATES OVERLAP D and A: \n",
      " (0.020845005699072532+2.8189256484623115e-18j)\n",
      "ORTHOGONAL STATES OVERLAP R and L: \n",
      " (0.0009738355751265637-3.469446951953614e-18j)\n",
      "\n",
      "\n",
      "ORTHOGONAL STATES OVERLAP H and D: \n",
      " (0.5051948336412709-2.0816681711721685e-17j)\n",
      "ORTHOGONAL STATES OVERLAP H and L: \n",
      " (0.5055592420584687-5.551115123125783e-17j)\n",
      "ORTHOGONAL STATES OVERLAP D and L: \n",
      " (0.4490729386975336-3.8163916471489756e-17j)\n",
      "ORTHOGONAL STATES OVERLAP H and R: \n",
      " (0.5155140449305741+1.942890293094024e-16j)\n",
      "ORTHOGONAL STATES OVERLAP H and A: \n",
      " (0.47629812997426024+3.469446951953614e-17j)\n"
     ]
    }
   ],
   "source": [
    "rhoIn=[]\n",
    "rhoOUT=[]\n",
    "Lambdas=[]\n",
    "Rs=[]\n",
    "pass_prob=[]\n",
    "\n",
    "input_number=6\n",
    "mbasis_number=6\n",
    "\n",
    "oput=np.zeros((mbasis_number,1,2), dtype=complex)\n",
    "iput=np.zeros((input_number,1,2), dtype=complex)\n",
    "# The order of state: D L H A R V (To match the order we use below that is already too deep in the code)\n",
    "oput[2]=H=np.array([1,0]) #z\n",
    "oput[5]=V=np.array([0,1]) #e\n",
    "oput[0]=D=np.array([1,1])/np.sqrt(2) #a\n",
    "oput[3]=A=np.array([1,-1])/np.sqrt(2) #c\n",
    "oput[1]=L=np.array([1,1j])/np.sqrt(2) #y\n",
    "oput[4]=R=np.array([1,-1j])/np.sqrt(2) #f\n",
    "\n",
    "numberofchannels=8\n",
    "counts=np.zeros((numberofchannels,input_number,2,3), dtype=int)\n",
    "counts_aux=np.zeros((input_number,2,3), dtype=float)\n",
    "heralding_single=np.zeros((input_number,3), dtype=int)\n",
    "sigma_counts=np.zeros((input_number,2,3), dtype=float)\n",
    "xp_counts=np.zeros((input_number,3,2), dtype=int)\n",
    "dirinv=np.zeros((input_number,2,2), dtype=complex)\n",
    "efficiencies=np.zeros(8, dtype=float)\n",
    "\n",
    "qubit_number=1\n",
    "repetitions=2e7 ### Not sure how to determine this\n",
    "\n",
    "Pauli=np.asarray([\n",
    "    [[1,0],\n",
    "    [0,1]],\n",
    "\n",
    "\n",
    "    [[0,1],\n",
    "    [1,0]],\n",
    "\n",
    "\n",
    "    [[0,-1j],\n",
    "    [1j,0]],\n",
    "\n",
    "\n",
    "    [[1,0],\n",
    "    [0,-1]]])\n",
    "\n",
    "def FindingFile(containing, filenames):\n",
    "    for file in filenames:\n",
    "         if fnmatch.fnmatch(file, 'Bigiteration_0_'+containing+'_*'):\n",
    "            return file\n",
    "    print('No file containing: Bigiteration_0_', containing, '...')\n",
    "    pass\n",
    "\n",
    "### Loading data ###\n",
    "#for j in range(input_number):\n",
    "\n",
    "### State tomography ### \n",
    "for j in range(input_number):\n",
    "    ### Order of the input states in the analysis: 0=H 1=V 2=D 3=L 4=A 5=R\n",
    "    if j==0:\n",
    "        print(\"Input state 0: |HxH|\")\n",
    "        iput[j]=H\n",
    "        rhoIn.append(np.outer(H,np.conjugate(H))) \n",
    "    if j==1:\n",
    "        print(\"Input state 1: |VxV|\") \n",
    "        iput[j]=V     \n",
    "        rhoIn.append(np.outer(V,np.conjugate(V))) \n",
    "    if j==2:\n",
    "        print(\"Input state 2: |DxD|\")  \n",
    "        iput[j]=D\n",
    "        rhoIn.append(np.outer(D,np.conjugate(D)))     \n",
    "    if j==3:\n",
    "        print(\"Input state 3: |LxL|\")\n",
    "        iput[j]=L\n",
    "        rhoIn.append(np.outer(L,np.conjugate(L)))\n",
    "    if j==4:\n",
    "        print(\"Input state 4: |AxA|\")\n",
    "        iput[j]=A\n",
    "        rhoIn.append(np.outer(A,np.conjugate(A)))\n",
    "    if j==5:\n",
    "        print(\"Input state 5: |RxR|\")\n",
    "        iput[j]=R\n",
    "        rhoIn.append(np.outer(R,np.conjugate(R)))\n",
    "        \n",
    "    ######## Simulated counts using Simon's tomography functions ##########\n",
    "    ### data is saved as \"Bigiteration_0_xy\" with x(y) being the measurement(input) basis\n",
    "    bases=np.array([\n",
    "        [MBasisList[0]+IBasisList[j],MBasisList[1]+IBasisList[j],MBasisList[2]+IBasisList[j]]])#, ## order: D, L, H\n",
    "\n",
    "    os.chdir(working_dir+'\\ProcessTomoData')\n",
    "    filenames = [i for i in glob.glob(\"Bigiteration_0_*\")]\n",
    "\n",
    "    #for v in range(2):\n",
    "    for w in range(3):\n",
    "        file=FindingFile(bases[0][w], filenames)\n",
    "        with open(file) as file: \n",
    "            for line in file:\n",
    "                fields = line.split()\n",
    "                for iter in range (len(fields)):\n",
    "                    # In counts[a][b][c][d], 'a' corresponds to the channel (in order): 1 2 3 4 13 14 23 24 (defined in pseudo)\n",
    "                    counts[iter][j][0][w]=fields[iter]\n",
    "                    if w>0: #and v<1:\n",
    "                        efficiencies[iter]+=float(fields[iter])\n",
    "        counts_aux[j][0][w]=counts[-2][j][0][w] ##Channel 3 is the one recording the counts for the positive eigenvalue\n",
    "        counts_aux[j][1][w]=counts[-1][j][0][w] ##Channel 4 is the one recording the counts for the negative eigenvalue\n",
    "        heralding_single[j][w]=counts[1][j][0][w]    \n",
    "\n",
    "### Normalizing the counts with the detectors efficiencies ###\n",
    "efficiencies=efficiencies/np.max(efficiencies)\n",
    "aux=0\n",
    "for j in range(input_number):\n",
    "    for w in range(3):\n",
    "        heralding_single[j][w]=heralding_single[j][w]/efficiencies[1]\n",
    "        counts_aux[j][0][w]=1e6*counts_aux[j][0][w]/float(efficiencies[-2]*heralding_single[j][w])\n",
    "        counts_aux[j][1][w]=1e6*counts_aux[j][1][w]/float(efficiencies[-1]*heralding_single[j][w])\n",
    "\n",
    "        if (aux<(counts_aux[j][0][w]+counts_aux[j][1][w])):#/heralding_single[j][w]):\n",
    "            aux=(counts_aux[j][0][w]+counts_aux[j][1][w])#/heralding_single[j][w]\n",
    "        \n",
    "for j in range(input_number):\n",
    "    for w in range(3):\n",
    "        print('Input: ', BasesI[j], anglesInput[j], 'Output: ', BasesO[w], anglesOutput[w], 'Sum of counts normalized: ', (counts_aux[j][0][w]+counts_aux[j][1][w])/aux)#(heralding_single[j][w]*aux))\n",
    "        \n",
    "for j in range(input_number):\n",
    "    xp_counts[j][:][:]=np.array(np.transpose(counts_aux[j][:][:])) # get the experimental counts\n",
    "\n",
    "    Iout=np.sum(counts_aux.flatten(), dtype = np.float32)\n",
    "    pass_prob.append(Iout/(3*repetitions))\n",
    "\n",
    "    statetomo=LRETomography(int(qubit_number), xp_counts[j][:][:], working_dir)\n",
    "    statetomo.run() ### Runs fast maximum likelihood estimation\n",
    "    statetomo.quantum_state.get_density_matrix()\n",
    "    dirinv[j][:][:]=statetomo.quantum_state.get_density_matrix()\n",
    "    print('State:',  iput[j])\n",
    "    print('Fast maximum likelihood estimation: \\n', dirinv[j][:][:], '\\n')  \n",
    "    \n",
    "    if j<4:\n",
    "        a = np.array([[1, 1],[1,-1]])\n",
    "        b = np.array([dirinv[j][0][0], dirinv[j][1][1]])\n",
    "        sol_L = np.linalg.solve(a,b)\n",
    "\n",
    "        e = np.array([[1, -1j],[1,+1j]])\n",
    "        f = np.array([dirinv[j][0][1], dirinv[j][1][0]])\n",
    "        sol_I = np.linalg.solve(e,f)\n",
    "\n",
    "        c = np.array([[1, 1],[1,-1]])\n",
    "        d = np.array([rhoIn[j][0][0], rhoIn[j][1][1]])\n",
    "        sol_R = np.linalg.solve(c,d)\n",
    "        \n",
    "        Lambdas.append([sol_L[0],sol_I[0],sol_I[1],sol_L[1]])\n",
    "        Rs.append([sol_R[0],np.real(rhoIn[j][1][0]),np.imag(rhoIn[j][1][0]),sol_R[1]])\n",
    "\n",
    "        # Considering the losses, we multiply the density matrix by the probability of measuring a photon\n",
    "        #print('Lambdas and pass probability: ', Lambdas[j][:], pass_prob[j])\n",
    "        Lambdas[j][:]=np.array(Lambdas[j][:])*pass_prob[j]\n",
    "        \n",
    "iterator = get_iterator(4,3)\n",
    "B=np.zeros((4,4,4,4), dtype=complex)\n",
    "\n",
    "print('\\n \\n \\n')\n",
    "print('ORTHOGONAL STATES OVERLAP V and H: \\n', np.trace(dirinv[0][:][:]@dirinv[1][:][:]))\n",
    "print('ORTHOGONAL STATES OVERLAP D and A: \\n', np.trace(dirinv[2][:][:]@dirinv[4][:][:]))\n",
    "print('ORTHOGONAL STATES OVERLAP R and L: \\n', np.trace(dirinv[3][:][:]@dirinv[5][:][:]))\n",
    "print('\\n')\n",
    "print('ORTHOGONAL STATES OVERLAP H and D: \\n', np.trace(dirinv[0][:][:]@dirinv[2][:][:]))\n",
    "print('ORTHOGONAL STATES OVERLAP H and L: \\n', np.trace(dirinv[0][:][:]@dirinv[3][:][:]))\n",
    "print('ORTHOGONAL STATES OVERLAP D and L: \\n', np.trace(dirinv[2][:][:]@dirinv[3][:][:]))\n",
    "print('ORTHOGONAL STATES OVERLAP H and R: \\n', np.trace(dirinv[0][:][:]@dirinv[5][:][:]))\n",
    "print('ORTHOGONAL STATES OVERLAP H and A: \\n', np.trace(dirinv[0][:][:]@dirinv[4][:][:]))\n",
    "\n",
    "for m, n, j in iterator:\n",
    "    temp = np.zeros((2,2), dtype=complex)\n",
    "    for i in range(4):\n",
    "        temp += (Rs[j][i]*Pauli[m]@Pauli[i]@Pauli[n])\n",
    "\n",
    "    a = np.array([[1, 1],[1,-1]])\n",
    "    b = np.array([temp[0][0],temp[1][1]])\n",
    "    sol_diagonal = np.linalg.solve(a,b)\n",
    "    c = np.array([[1, -1j],[1,1j]])\n",
    "    d = np.array([temp[0][1],temp[1][0]])\n",
    "    sol_anti_diagonal = np.linalg.solve(c,d)\n",
    "    B[m][n][j][0]=sol_diagonal[0]\n",
    "    B[m][n][j][1]=sol_anti_diagonal[0]\n",
    "    B[m][n][j][2]=sol_anti_diagonal[1]\n",
    "    B[m][n][j][3]=sol_diagonal[1]\n",
    "\n",
    "    # Verification step\n",
    "    ver=B[m][n][j][0]*Pauli[0]+B[m][n][j][1]*Pauli[1]+B[m][n][j][2]*Pauli[2]+B[m][n][j][3]*Pauli[3]==temp\n",
    "    if False in ver:\n",
    "        print('B matrix is not verifying right condidion')\n",
    "\n",
    "Bs_new = np.transpose(np.reshape(B,(16,16)))\n",
    "\n",
    "Kabba=np.linalg.inv(Bs_new) \n",
    "\n",
    "lambdas_vect=np.reshape(Lambdas,[16,1])\n",
    "\n",
    "Chi_vector=Kabba@lambdas_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complex_to_real(z):      # complex vector of length n -> real of length 2n\n",
    "    return np.concatenate((np.real(z), np.imag(z)))\n",
    "\n",
    "def real_to_complex(z):      # real vector of length 2n -> complex of length n\n",
    "    return z[:len(z)//2] + 1j * z[len(z)//2:]\n",
    "\n",
    "#The function \"conversion\" converts the Chi vector from: 1 vector: 16 reals + 16 imag params;\n",
    "                                        #to: 2 vectors: 1 real with 10 params + 1 imag with 6 params\n",
    "#This is to make sure Chi is Hermitian in it's structure, reducing the number of free params in the optimization process\n",
    "def conversion(X):\n",
    "    X_real=np.array([[X[0],X[1],X[2],X[3]],\n",
    "                    [X[1],X[5],X[6],X[7]],\n",
    "                    [X[2],X[6],X[10],X[11]],\n",
    "                    [X[3],X[7],X[11],X[15]]]).flatten()\n",
    "    X_imag=np.array([[0.0,X[17],X[18],X[19]],\n",
    "                    [-X[17],0.0,X[22],X[23]],\n",
    "                    [-X[18],-X[22],0.0,X[27]],\n",
    "                    [-X[19],-X[23],-X[27],0.0]]).flatten()\n",
    "    return(X_real, X_imag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(X, *args):\n",
    "    \n",
    "    counts=args\n",
    "    f_min=0\n",
    "    counts=np.reshape(counts, (input_number, mbasis_number)) #This reshapes counts to [j][o], j is input (order: V, H, D, R, A, L) and o is measurement basis (order: D R V A L H)\n",
    "    X_real, X_imag = conversion(X)\n",
    "    \n",
    "    for j in range(input_number):\n",
    "        for o in range(mbasis_number):\n",
    "            # Defining n as a probability of measurement outcome\n",
    "            nab=counts[j][o]\n",
    "            soma=0+0j\n",
    "            for m in range(4):\n",
    "                for n in range(4):\n",
    "                    t=n%4+4*(m%4)\n",
    "                    soma += (X_real[t]+1j*X_imag[t])*np.conjugate(oput[o])@Pauli[m]@rhoIn[j]@Pauli[n]@np.transpose(oput[o])\n",
    "            soma_f = np.abs(soma[0][0])\n",
    "            f_min += ((nab-soma_f*repetitions)**2)/float(nab)\n",
    "    return f_min\n",
    "\n",
    "Chi_initial=complex_to_real(Chi_vector).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P_matrix returns the P 2x2 matrix, that determins es the probability of a certain state being measured (not lost)\n",
    "def P_matrix(X):\n",
    "    X_real, X_imag = conversion(X)\n",
    "    \n",
    "    soma_c=np.zeros((2,2), dtype=complex)\n",
    "    for m_c in range(4):\n",
    "        for n_c in range(4):\n",
    "            t_c=n_c%4+4*(m_c%4)\n",
    "            soma_c += (X_real[t_c]+1j*X_imag[t_c])*Pauli[n_c]@Pauli[m_c]\n",
    "    #if np.imag(np.trace(soma_c))>1e-17:\n",
    "        #print('Imaginary part of trace is too big: ', np.imag(np.trace(soma_c)))\n",
    "    return soma_c\n",
    "\n",
    "# X_matrix returns the Chi 4x4 matrix (n are columns and m are lines)\n",
    "def X_matrix(X):\n",
    "    X_real, X_imag = conversion(X)\n",
    "    \n",
    "    a=np.append(X_real,X_imag)\n",
    "    b=real_to_complex(a)\n",
    "    c=np.reshape(b,(4,4))\n",
    "    return(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining of the constraints (equalities and inequalities) we want to impose in the optimization process\n",
    "from mystic.penalty import quadratic_inequality,quadratic_equality\n",
    "\n",
    "def neg_part(Y):\n",
    "    return np.sum(np.clip(Y, -np.inf, 0))\n",
    "\n",
    "# Making sure the channel is trace-preserving or trace-decreasing\n",
    "def penalty1 (X):\n",
    "    return np.real(np.trace(P_matrix(X)))-2\n",
    "#def penalty2 (X):\n",
    "#    return -neg_part(np.real(np.linalg.eig(X_matrix(X))[0]))\n",
    "\n",
    "# Making sure the eigenvalues o Chi are positive\n",
    "def penalty2 (X):\n",
    "    return -np.real(np.linalg.eig(X_matrix(X))[0])[0]\n",
    "def penalty3 (X):\n",
    "    return -np.real(np.linalg.eig(X_matrix(X))[0])[1]\n",
    "def penalty4 (X):\n",
    "    return -np.real(np.linalg.eig(X_matrix(X))[0])[2]\n",
    "def penalty5 (X):\n",
    "    return -np.real(np.linalg.eig(X_matrix(X))[0])[3]\n",
    "\n",
    "#def penalty3(X):\n",
    "#\treturn neg_part(np.imag(np.linalg.eig(P_matrix(X))[0]))\n",
    "\n",
    "# Making sure the eigenvalues o Chi are real\n",
    "def penalty6(X):\n",
    "\treturn np.imag(np.linalg.eig(X_matrix(X))[0])[0]\n",
    "def penalty7(X):\n",
    "\treturn np.imag(np.linalg.eig(X_matrix(X))[0])[1]\n",
    "def penalty8(X):\n",
    "\treturn np.imag(np.linalg.eig(X_matrix(X))[0])[2]\n",
    "def penalty9(X):\n",
    "\treturn np.imag(np.linalg.eig(X_matrix(X))[0])[3]\n",
    "\n",
    "\n",
    "@quadratic_inequality(penalty1, k=1e15)\n",
    "@quadratic_inequality(penalty2, k=1e15)\n",
    "@quadratic_inequality(penalty3, k=1e15)\n",
    "@quadratic_inequality(penalty4, k=1e15)\n",
    "@quadratic_inequality(penalty5, k=1e15)\n",
    "\n",
    "@quadratic_equality(penalty6, k=1e15)\n",
    "@quadratic_equality(penalty7, k=1e15)\n",
    "@quadratic_equality(penalty8, k=1e15)\n",
    "@quadratic_equality(penalty9, k=1e15)\n",
    "\n",
    "def penalty(x):\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FUNCTION:  904105454.4890084\n",
      "PENALTY:  589362074816.9025\n"
     ]
    }
   ],
   "source": [
    "Chi_initial=complex_to_real(Chi_vector).flatten()\n",
    "# For perfect data the Chi matrix should be correctly inverted and the f should output 0\n",
    "print('FUNCTION: ', f(Chi_initial, counts_aux))\n",
    "print('PENALTY: ', penalty(Chi_initial))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0 has ChiSquare: 159586406279.988190\n",
      "Generation 50 has ChiSquare: 4043150.194254\n",
      "Generation 100 has ChiSquare: 1022212.482235\n",
      "Generation 150 has ChiSquare: 293033.155757\n",
      "Generation 200 has ChiSquare: 86628.293376\n",
      "Generation 250 has ChiSquare: 45654.982088\n",
      "Generation 300 has ChiSquare: 25676.255016\n",
      "Generation 350 has ChiSquare: 22950.483307\n",
      "Generation 400 has ChiSquare: 22078.140251\n",
      "Generation 450 has ChiSquare: 21843.072577\n",
      "Generation 500 has ChiSquare: 21736.391844\n",
      "Generation 550 has ChiSquare: 21718.791600\n",
      "Generation 600 has ChiSquare: 21718.791600\n",
      "Generation 650 has ChiSquare: 21700.898813\n",
      "Generation 700 has ChiSquare: 21700.898813\n",
      "STOP(\"ChangeOverGeneration with {'tolerance': 1e-20, 'generations': 100}\")\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 21700.898813\n",
      "         Iterations: 738\n",
      "         Function evaluations: 36950\n"
     ]
    }
   ],
   "source": [
    "## Running the optimization\n",
    "monitor = VerboseMonitor(50)\n",
    "npop = 50\n",
    "result_y=diffev2(f, x0=Chi_initial, args=counts_aux, strategy=Best1Bin, bounds=[(-1,1)]*32, penalty=penalty, npop=npop, gtol=100, disp=True, ftol=1e-20, itermon=monitor, handler=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization (getting rid of the global losses)\n",
    "Chi_initial_n=Chi_initial/float(np.max(np.real(np.linalg.eig(P_matrix(Chi_initial))[0])))\n",
    "Chii_final_n=result_y/float(np.max(np.real(np.linalg.eig(P_matrix(result_y))[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The eigenvalue cannot be complex! The result cannot be trusted! \n",
      " [0.10058977-1.58640665e-18j 0.09979006+1.58640665e-18j]\n"
     ]
    }
   ],
   "source": [
    "## Defining the conditions the final Chi matrix should follow\n",
    "def Trace_cond(X):\n",
    "    return np.trace(P_matrix(X))\n",
    "\n",
    "def Hermitian(X):\n",
    "    return P_matrix(X)[0][1]-np.conjugate(P_matrix(X)[1][0])\n",
    "\n",
    "def Eigenvalue(X):\n",
    "    return np.linalg.eig(P_matrix(X))[0]\n",
    "\n",
    "X=result_y\n",
    "result_y=np.append(conversion(X)[0],conversion(X)[1]).flatten()\n",
    "\n",
    "if np.imag(np.max(Eigenvalue(result_y)))==0:\n",
    "    Final_Chi_vector=real_to_complex(result_y/float(np.real(np.max(Eigenvalue(result_y)))))\n",
    "else:\n",
    "    print('The eigenvalue cannot be complex! The result cannot be trusted! \\n', Eigenvalue(result_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONDITIONS TO VERIFY: \n",
      "\n",
      "The eigenvalues of the initial guess are complex! \n",
      " [0.60156173-2.77555756e-17j 0.60156173+1.56125113e-17j] \n",
      "\n",
      "The eigenvalues of the final Chi are complex! Cannot trust the results \n",
      " [0.10058977-1.58640665e-18j 0.09979006+1.58640665e-18j] \n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Chi_final_n' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\LAURAM~1\\AppData\\Local\\Temp/ipykernel_25300/3495376049.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'The eigenvalues of the final Chi are complex! Cannot trust the results \\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEigenvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Trace of P normalized (should be <= 2): \\n i: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mP_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mChi_initial_n\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'\\n f: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mP_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mChi_final_n\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Eigenvalues of P matrix (normalized) (should be positive and <= 1): \\n i: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mP_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mChi_initial_n\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m,\u001b[0m\u001b[1;34m'\\n f: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mP_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mChi_final_n\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Function value (should be minimized): \\n i: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mChi_initial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcounts_aux\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'\\n f: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcounts_aux\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Chi_final_n' is not defined"
     ]
    }
   ],
   "source": [
    "## Printing the conditions the final Chi matrix should follow\n",
    "print('CONDITIONS TO VERIFY: \\n')\n",
    "\n",
    "if np.any(np.imag(Eigenvalue(Chi_initial)))!=0:\n",
    "    print('The eigenvalues of the initial guess are complex! \\n', Eigenvalue(Chi_initial), '\\n')\n",
    "    \n",
    "if np.any(np.imag(Eigenvalue(result_y)))!=0:\n",
    "    print('The eigenvalues of the final Chi are complex! Cannot trust the results \\n', Eigenvalue(result_y), '\\n')\n",
    "\n",
    "print('Trace of P normalized (should be <= 2): \\n i: ', np.trace(P_matrix(Chi_initial_n)), '\\n f: ', np.trace(P_matrix(Chi_final_n)), '\\n')\n",
    "print('Eigenvalues of P matrix (normalized) (should be positive and <= 1): \\n i: ', np.linalg.eig(P_matrix(Chi_initial_n))[0] ,'\\n f: ', np.linalg.eig(P_matrix(Chi_final_n))[0], '\\n')\n",
    "print('Function value (should be minimized): \\n i: ', f(Chi_initial, counts_aux), '\\n f: ', f(result_y, counts_aux), '\\n')\n",
    "print('Penalty value (should be minimized): \\n i: ', penalty(Chi_initial), '\\n f: ', penalty(result_y), '\\n')\n",
    "\n",
    "print('\\n\\n')\n",
    "\n",
    "print('ABOUT THE NON NORMALIZED P MATRIX: \\n')\n",
    "\n",
    "\n",
    "print('COND 1: Trace <= 2: ', Trace_cond(Chi_initial))\n",
    "print('COND 2: Hermitian = 0: ', Hermitian(Chi_initial))\n",
    "print('COND 6: Eigenvalue P matrix >= 0 && <=1: ', Eigenvalue(Chi_initial))\n",
    "print('P_matrix initial: \\n', P_matrix(Chi_initial))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('COND 1: Trace <= 2: ', Trace_cond(result_y))\n",
    "print('COND 2: Hermitian = 0: ', Hermitian(result_y))\n",
    "print('COND 6: Eigenvalue P >= 0 && <=1: ', Eigenvalue(result_y))\n",
    "print('P_matrix final: \\n', P_matrix(result_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Printing the input states and the transformation they go through when applied the process matrix\n",
    "## And printing the fidelity of the reconstructed density matrix with the ideal one\n",
    "## The ideal density matrix will depend on the generated data (check mathematica program)\n",
    "\n",
    "\n",
    "def Channel(X, initialstate):\n",
    "    X_real, X_imag = conversion(X)\n",
    "    \n",
    "    Final_state=np.zeros((2,2), dtype=complex)\n",
    "    for m in range (4):\n",
    "        for n in range(4):\n",
    "            t=n%4+4*(m%4)\n",
    "            Final_state += (X_real[t]+1j*X_imag[t])*Pauli[m]@initialstate@Pauli[n]\n",
    "    return Final_state\n",
    "\n",
    "def fidelity(ideal, real):\n",
    "    return ((np.trace(sqrtm(sqrtm(real)@ideal@sqrtm(real))))**2/(np.trace(ideal)*np.trace(real)))\n",
    "\n",
    "def Chi_ideal(Th, Tv):\n",
    "    r=np.array([[((np.sqrt(Th)+np.sqrt(Tv))**2)/4,0,0,(Tv-Th)/4],\n",
    "              [0, 0, 0, 0],\n",
    "              [0, 0, 0, 0],\n",
    "              [(Tv-Th)/4, 0, 0, ((np.sqrt(Tv)-np.sqrt(Th))**2)/4]])\n",
    "    return r\n",
    "\n",
    "def verification(X, Y):\n",
    "    for initial in range(input_number):\n",
    "        verification = rhoIn[initial]\n",
    "        Finali_state = Channel(Y, verification)\n",
    "        Finalf_state = Channel(X, verification)\n",
    "        print('INITIAL STATE: \\n', verification)\n",
    "        print('OUTPUT STATE: \\n', dirinv[initial][:][:])\n",
    "        print('FINAL STATE (Chi direct inversion): \\n', Finali_state)\n",
    "        print('FINAL STATE (Chi optmized): \\n', Finalf_state)\n",
    "        \n",
    "        print('TRACE: \\n i:', np.trace(Finali_state), '\\n f:', np.trace(Finalf_state))\n",
    "        \n",
    "        print('\\n \\n')\n",
    "\n",
    "    #F_i=fidelity(Chi_ideal(0.2,0.8), X_matrix(Y))\n",
    "    #F_f=fidelity(Chi_ideal(0.2,0.8), X_matrix(Y))\n",
    "    #print('FIDELITY TO THE IDEAL PROCESS MATRIX: \\n i: ', F_i, '\\n f: ', F_f)\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "verification(Chi_final_n, Chi_initial_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This code is suuposed to characterize a unitary transformation\n",
    "### Now that we have Chi, we want to find the closest unitary to que process matrix we found sunch that we can then calculate some distance between them\n",
    "bell=(np.array([1,0,0,0])+np.array([0,0,0,1]))/np.sqrt(2)\n",
    "bellmatrix=np.array(np.outer(bell, np.conjugate(bell)))\n",
    "\n",
    "def ApplyUnitaryToBell(U, dm):\n",
    "    return U@dm@np.transpose(np.conjugate(U))\n",
    "\n",
    "# Calculating the Choi–Jamiołkowski distance\n",
    "def ChannelCJ(X):\n",
    "    X_real, X_imag = conversion(X)\n",
    "    \n",
    "    Final_state=np.zeros((4,4), dtype=complex)\n",
    "    for m in range (4):\n",
    "        for n in range(4):\n",
    "            t=n%4+4*(m%4)\n",
    "            Final_state += (X_real[t]+1j*X_imag[t])*np.kron(Pauli[0],Pauli[m])@bellmatrix@np.kron(Pauli[0],Pauli[n])\n",
    "    return Final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho_jE=ChannelCJ(Chi_final_n)\n",
    "#print(rho_jE)\n",
    "\n",
    "def GeneralUnitary(x):\n",
    "    return np.array([[np.exp(1j*x[0])*np.cos(x[2]), np.exp(1j*x[1])*np.sin(x[2])],[-np.exp(-1j*x[1])*np.sin(x[2]), np.exp(-1j*x[0])*np.cos(x[2])]])\n",
    "\n",
    "def fUnitary(x, *args):\n",
    "    U=GeneralUnitary(x)\n",
    "    return -np.abs(fidelity(rho_jE, ApplyUnitaryToBell(np.kron(Pauli[0],U), bellmatrix)))\n",
    "\n",
    "monitor = VerboseMonitor(50)\n",
    "npop = 50\n",
    "result_w=diffev2(fUnitary, x0=np.array([0, 0, 0]), args=rho_jE, strategy=Best1Bin, bounds=[(-np.pi,np.pi)]*3, npop=npop, gtol=100, disp=True, ftol=1e-30, itermon=monitor, handler=False)\n",
    "print('\\n The parameters are: ', result_w)\n",
    "print('\\n The closest unitary to our process matrix is: \\n', GeneralUnitary(result_w))\n",
    "print('\\n with a fidelity of: ', -fUnitary(result_w, rho_jE))\n",
    "### Note that when the x[2] is a multiple of pi/2, one of x[0] or x[1] can take any value because 0*e^(i*phi)=0 for any phi (This is obvious but I forgot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ERROR DUE TO WAVEPLATES UNCERTAINTY ###\n",
    "## In our xp_counts matrix, every entry corresponds to a different projection basis, which is associated to associated to\n",
    "## a different set of {HWP,QWP}. We need to simulate new number of counts for each entry, given the angle and the\n",
    "## the uncertainty of the WP's we are using\n",
    "\n",
    "HWP_dict={\"d\": np.pi/8,\n",
    "          \"l\": 0,\n",
    "          \"v\": 0,\n",
    "          \"a\": -np.pi/8,\n",
    "          \"r\": 0,\n",
    "          \"h\": np.pi/4}\n",
    "\n",
    "QWP_dict={\"d\": np.pi/2,\n",
    "          \"l\": 3*np.pi/4,\n",
    "          \"v\": np.pi/2,\n",
    "          \"a\": np.pi/2,\n",
    "          \"r\": np.pi/4,\n",
    "          \"h\": np.pi/2}\n",
    "\n",
    "projector_dict={\"d\": np.array([1,1])/np.sqrt(2),\n",
    "                \"l\": np.array([1,1j])/np.sqrt(2),\n",
    "                \"v\": np.array([1,0]),\n",
    "                \"a\": np.array([1,-1])/np.sqrt(2),\n",
    "                \"r\": np.array([1,-1j])/np.sqrt(2),\n",
    "                \"h\": np.array([0,1])}\n",
    "\n",
    "\n",
    "ob=np.transpose(np.array([['dd', 'dl', 'dv', 'ld', 'll', 'lh', 'vd', 'vl', 'vv'],\n",
    "                       ['da', 'dr', 'dh', 'la', 'lr', 'lh', 'va', 'vr', 'vh'],\n",
    "                       ['ad', 'al', 'av', 'rd', 'rl', 'rv', 'hd', 'hl', 'hv'],\n",
    "                       ['aa', 'ar', 'ah', 'ra', 'rr', 'rh', 'ha', 'hr', 'hh']]))\n",
    "\n",
    "lines, columns = np.shape(ob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Uncertainty on the WP\n",
    "sigma_hwp_arya=0.04*np.pi/180\n",
    "sigma_qwp_arya=0.1*np.pi/180\n",
    "sigma_hwp_cersei=0.01*np.pi/180\n",
    "sigma_qwp_cersei=0.11*np.pi/180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defining the number of simulated runs\n",
    "error_runs=1000\n",
    "mu=np.zeros((n_files))\n",
    "std=np.zeros((n_files))\n",
    "\n",
    "for index in range(n_files):\n",
    "    xp_counts_err=np.zeros((3**qubit_number,2**qubit_number), dtype=int)\n",
    "    dm_sim_WP=np.zeros((2**qubit_number,2**qubit_number), dtype=complex)\n",
    "\n",
    "    dm_sim=np.zeros((error_runs, 2**qubit_number,2**qubit_number), dtype=complex)\n",
    "    dm_err=np.zeros((error_runs, 2**qubit_number,2**qubit_number), dtype=complex)\n",
    "\n",
    "    fidelity_sim=np.zeros((error_runs), dtype=float)\n",
    "\n",
    "    ### For each run we simulate the number of counts we could have within poissionian error and calculate\n",
    "    ### the correspondent density matrix. With each matrix corresponding to an experimental run, we calculate the fidelity\n",
    "    ### to the Bell state\n",
    "    for i in range(error_runs):\n",
    "        for k in range(lines):\n",
    "            N_total=np.sum(xp_counts[k])\n",
    "            for l in range(columns):\n",
    "                proj=['vv', 'vh', 'hv', 'hh']\n",
    "\n",
    "                proj_basis=ob[k][0]\n",
    "                angle_hwp_arya=np.random.normal(loc=HWP_dict[proj_basis[0]], scale=sigma_hwp_arya, size=None)\n",
    "                angle_qwp_arya=np.random.normal(loc=QWP_dict[proj_basis[0]], scale=sigma_qwp_arya, size=None)\n",
    "                angle_hwp_cersei=np.random.normal(loc=HWP_dict[proj_basis[1]], scale=sigma_hwp_cersei, size=None)\n",
    "                angle_qwp_cersei=np.random.normal(loc=QWP_dict[proj_basis[1]], scale=sigma_qwp_cersei, size=None)\n",
    "\n",
    "                r_arya=WP_rotation(angle_qwp_arya,np.pi/2)@WP_rotation(angle_hwp_arya,np.pi)\n",
    "                r_cersei=WP_rotation(angle_qwp_cersei,np.pi/2)@WP_rotation(angle_hwp_cersei,np.pi)\n",
    "\n",
    "                ### Here we need to calculate the probability for a given projector and with that calculate N_total\n",
    "                ### for the xp_counts matrix and then we apply poissonian noise\n",
    "                MB_change=np.kron(r_arya,r_cersei)\n",
    "\n",
    "                dm_sim_WP=MB_change@Optimized_matrix[index]@np.transpose(np.conjugate(MB_change))\n",
    "                proj_basis_array=np.kron(projector_dict[proj[l][0]],projector_dict[proj[l][1]])\n",
    "\n",
    "                p=proj_basis_array@dm_sim_WP@np.transpose(np.conjugate(proj_basis_array))\n",
    "\n",
    "                xp_counts_err[k][l]=np.random.poisson(lam=p*N_total)\n",
    "\n",
    "        statetomo_err=LRETomography(int(qubit_number), xp_counts_err, \"C:\\\\Users\\\\LauraMartins\\\\Documents\\\\PhD\\\\Lab\\\\Code\\\\Tomographies\")\n",
    "        statetomo_err.run() ### Runs fast maximum likelihood estimation\n",
    "        statetomo_err.quantum_state.get_density_matrix()\n",
    "        dm_sim[i]=statetomo_err.quantum_state.get_density_matrix()\n",
    "\n",
    "        fidelity_sim[i]=fidelity(bell, dm_sim[i])\n",
    "    mu[index], std[index] = norm.fit(fidelity_sim)\n",
    "    print('Fidelity: ', np.round(mu[index],5), '\\n Uncertainty: ', np.round(std[index],5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
