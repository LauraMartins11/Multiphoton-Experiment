{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import time\n",
    "import math\n",
    "from scipy.stats import norm\n",
    "\n",
    "import mystic\n",
    "from mystic.solvers import DifferentialEvolutionSolver, diffev2\n",
    "from mystic.strategy import Best1Bin\n",
    "from mystic.monitors import Monitor,VerboseMonitor\n",
    "from copy import deepcopy\n",
    "\n",
    "from tomography import *\n",
    "\n",
    "from NestedForLoop import get_iterator\n",
    "from pathlib import Path\n",
    "from scipy.linalg import sqrtm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.optimize import least_squares\n",
    "\n",
    "import fnmatch\n",
    "from efficiencies import finding_file, get_channels_eff, set_raw_counts\n",
    "from optimization import Optimizer, function_fidelity, FidelityResults\n",
    "from constants import *\n",
    "\n",
    "from densitymatrix import DensityMatrix, apply_unitary_to_dm, GHZ\n",
    "\n",
    "from pathlib import Path\n",
    "import fnmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "######################################################################################################\n",
    "#----- COUNTING THE FILES AND SAVING THEM IN AN ARRAY TO MAKES THE REST OF THE ANALYSIS EASIER -------\n",
    "######################################################################################################\n",
    "\n",
    "n_files=0\n",
    "working_dir=r\"C:\\Users\\nicol\\Desktop\\Experiment\"\n",
    "os.chdir(working_dir)\n",
    "\n",
    "filenames = [i for i in glob.glob(\"StateTomography_2Layers_*\")]\n",
    "filenames.sort(key=os.path.getmtime)\n",
    "\n",
    "index_to_file = {}\n",
    "\n",
    "for index, filename in enumerate(filenames):\n",
    "    os.chdir(f\"{working_dir}\\\\{filename}\")\n",
    "    filenames_aux=[i for i in glob.glob(\"StateTomo_2Layers*\")]\n",
    "    for index_second, filenames_aux_second in enumerate(filenames_aux):\n",
    "        index_to_file[n_files] = f\"{filename}\\\\{filenames_aux_second}\"\n",
    "        n_files+=1\n",
    "os.chdir(working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting the efficiences\n",
      "Getting the counts\n",
      "Doing the Tomography\n",
      "Optimizing the state\n",
      "file, fidelity, fidelity_mean, fidelity_std:  StateTomography_2Layers_20230330\\StateTomo_2Layers (0.97468+0j)\n",
      "Getting the efficiences\n",
      "Getting the counts\n",
      "Doing the Tomography\n",
      "Optimizing the state\n",
      "file, fidelity, fidelity_mean, fidelity_std:  StateTomography_2Layers_20230330\\StateTomo_2Layers (0.95639-0j)\n"
     ]
    }
   ],
   "source": [
    "############################\n",
    "#----- INITIALISATION------#\n",
    "############################\n",
    "\n",
    "\n",
    "players_ini=[\"Bran\", \"Arya\", \"Cersei\", \"Dany\"]\n",
    "\n",
    "column_start_ini = [8,12]\n",
    "\n",
    "column_stop_ini = [12,16]\n",
    "\n",
    "column_start_2_emissions_ini=[16,20]\n",
    "\n",
    "column_stop_2_emissions_ini=[20,24]\n",
    "\n",
    "qubit_number=2\n",
    "\n",
    "error_runs=2\n",
    "\n",
    "States = {}\n",
    "    \n",
    "Beam = ['low','high']\n",
    "\n",
    " \n",
    "    \n",
    "for i in range (2):\n",
    "    \n",
    "    os.chdir(working_dir)\n",
    "\n",
    "    ## Defining the columns of the data file we want to use as data to reconstruct the density matrix (eg.: HH HV VH and VV basis)\n",
    "    column_start =column_start_ini[i]\n",
    "    column_stop = column_stop_ini[i]\n",
    "    \n",
    "    column_start_2_emissions= column_start_2_emissions_ini[i]\n",
    "    column_stop_2_emissions= column_stop_2_emissions_ini[i]\n",
    "\n",
    "    state_after=[]\n",
    "    state_after_file=[]\n",
    "\n",
    "    state_before=[]\n",
    "    state_before_file=[]\n",
    "\n",
    "    state = []\n",
    "    state_file=[]\n",
    "\n",
    "    xp_counts_corrected_with_eff=[]\n",
    "\n",
    "    statetomo = []\n",
    "    Fock_state = []\n",
    "  \n",
    "    U=[]\n",
    "    bell_aux=[]\n",
    "    target_ini=[]\n",
    "    players = players_ini[0+i*2:2+i*2]\n",
    "    \n",
    "\n",
    "    #####################################################################\n",
    "    #---------------------- STATE TOMOGRAPHY FOR THE FIRST PAIR----------\n",
    "    #####################################################################\n",
    "    for index in range(len(index_to_file)):\n",
    "        os.chdir(f\"{working_dir}\\\\{index_to_file[index]}\\\\\")\n",
    "        datafiles=[i for i in glob.glob(\"*\")]\n",
    "\n",
    "        ### Calculating the efficiencies of each detector\n",
    "        \n",
    "        print(\"Getting the efficiences\")\n",
    "        \n",
    "        efficiencies=get_channels_eff(datafiles, column_start, column_stop, os.getcwd())\n",
    "\n",
    "        ### Opening the data files and writing the data in counts_aux array\n",
    "        \n",
    "        print(\"Getting the counts\")\n",
    "        \n",
    "        counts_aux=set_raw_counts(datafiles, qubit_number, column_start, column_stop, os.getcwd())\n",
    "        xp_counts=np.array(np.transpose(counts_aux))\n",
    "    \n",
    "        counts_aux_2_emissions=set_raw_counts(datafiles, qubit_number, column_start_2_emissions, column_stop_2_emissions, os.getcwd())\n",
    "        xp_counts_2_emissions=np.array(np.transpose(counts_aux_2_emissions))\n",
    "\n",
    "        \n",
    "\n",
    "        print(\"Doing the Tomography\")\n",
    "        \n",
    "        \n",
    "        statetomo.append(LRETomography(int(qubit_number),xp_counts, xp_counts_2_emissions))\n",
    "        statetomo[-1].run(correct_eff=efficiencies)\n",
    "        #     statetomo[-1].run(print_nc=False)\n",
    "        xp_counts_corrected_with_eff.append(statetomo[-1].xp_counts)\n",
    "\n",
    "\n",
    "        ## The 'e' and 'r' serve to distinguish between tomography before and after, respectively\n",
    "        ## We want to save them in different arrays because we need them for different things\n",
    "    #     elif index_to_file[index][-8]=='e':\n",
    "    #         state_before.append(statetomo[-1])#.state)\n",
    "    #         state_before_file.append(index_to_file[index])\n",
    "    #         #print('\\n Fast maximum likelihood estimation: \\n', state_before[-1], '\\n')\n",
    "\n",
    "    #     elif index_to_file[index][-8]=='r':\n",
    "    #         state_after.append(statetomo[-1])#.state)\n",
    "    #         state_after_file.append(index_to_file[index])\n",
    "    #         #print('\\n Fast maximum likelihood estimation: \\n', state_after[-1], '\\n')\n",
    "\n",
    "        state.append(statetomo[-1])#.state)\n",
    "        state_file.append(index_to_file[index])\n",
    "        \n",
    "    states=state\n",
    "    bell=(np.array([0,0,0,1])+np.array([1,0,0,0]))/np.sqrt(2)\n",
    "    bellmatrix=np.array(np.outer(bell, np.conjugate(bell)))\n",
    "    fid=np.zeros((n_files))\n",
    "    \n",
    "    \n",
    "    print(\"Optimizing the state\")\n",
    "    \n",
    "    \n",
    "    optimized_matrix=np.zeros((n_files,2**qubit_number,2**qubit_number), dtype='complex')\n",
    "    \n",
    "    guess=np.array([0, 0, 0])\n",
    "    bounds=[(-np.pi,np.pi)]*3\n",
    "    results = []\n",
    "\n",
    "    opt=Optimizer(guess, function_fidelity, results=FidelityResults)\n",
    "\n",
    "    for index in range(len(states)):\n",
    "        result=opt.optimize(states[index].state, bell, bounds=bounds)\n",
    "        results.append(result)\n",
    "        \n",
    "    for index in range(len(states)):\n",
    "        target=bellmatrix\n",
    "        target_ini.append(np.transpose(np.conjugate(bellmatrix)))\n",
    "        states_file=state_file\n",
    "        States['state_' + Beam[i] ] = results[-1].Density(results[-1].optimized_state.state)\n",
    "        states= States['state_' + Beam[i]]\n",
    "        \n",
    "        print('file, fidelity, fidelity_mean, fidelity_std: ',\n",
    "          states_file[index], np.round(states.fidelity(target_ini[-1]),5))\n",
    "    \n",
    "locals().update(States)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "#------------ CREATION OF THE BEAMSPLITTER ---------------#\n",
    "###########################################################\n",
    "\n",
    "X = np.array([[0,1],[1,0]])\n",
    "Z = np.array([[1,0],[0,-1]])\n",
    "PBS = np.bmat([[np.diag([1,1]),np.zeros((2,2))],[np.zeros((2,2)),X@Z]])\n",
    "swap = np.array([[1,0,0,0],[0,0,1,0],[0,1,0,0],[0,0,0,1]])\n",
    "PBS_swap = swap@PBS\n",
    "Beamsplitter = np.kron(np.diag([1,1]),np.kron(PBS_swap,np.diag([1,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging the two states\n",
      "Applying the Beam splitter\n"
     ]
    }
   ],
   "source": [
    "##################################################\n",
    "#------------ CREATION OF THE GHZ ---------------#\n",
    "##################################################\n",
    "\n",
    "print('Merging the two states')\n",
    "\n",
    "GHZ_state = []\n",
    "state_high.state_swap=[]\n",
    "target_GHZ_without_PBS = []\n",
    "swap = np.array([[0,0,1,0],[0,0,0,1],[1,0,0,0],[0,1,0,0]])\n",
    "state_high_swap = swap@state_high.state\n",
    "GHZ_state.append(GHZ(state_low.state,state_high_swap))\n",
    "GHZ_state[-1].GHZ_before_BS()\n",
    "\n",
    "print('Applying the Beam splitter')\n",
    "\n",
    "GHZ_state[-1].BeamSplitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file, fidelity ['StateTomography_2Layers_20230330\\\\StateTomo_2Layers'] (0.90881+0.02495j)\n"
     ]
    }
   ],
   "source": [
    "##########################################################\n",
    "#------------ CREATION OF THE TARGET STATE---------------#\n",
    "##########################################################\n",
    "\n",
    "target_bell = np.tensordot(((np.array([0,0,0,1])+np.array([1,0,0,0]))/np.sqrt(2)),((np.array([0,0,0,1])+np.array([1,0,0,0]))/np.sqrt(2)),axes=0)\n",
    "swap_target_bell = swap@target_bell\n",
    "target_GHZ_without_PBS = np.kron(target_bell,swap_target_bell)\n",
    "target_GHZ=Beamsplitter@target_GHZ_without_PBS\n",
    "\n",
    "print('file, fidelity',states_file, np.round(GHZ_state[-1].fidelity(target_GHZ),5))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
