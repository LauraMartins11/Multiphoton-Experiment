{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import time\n",
    "import math\n",
    "from scipy.stats import norm\n",
    "\n",
    "import mystic\n",
    "from mystic.solvers import DifferentialEvolutionSolver, diffev2\n",
    "from mystic.strategy import Best1Bin\n",
    "from mystic.monitors import Monitor,VerboseMonitor\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from Tomography import *\n",
    "\n",
    "from NestedForLoop import get_iterator\n",
    "from pathlib import Path\n",
    "from scipy.linalg import sqrtm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.optimize import least_squares\n",
    "\n",
    "import fnmatch\n",
    "from Efficiencies import finding_file, get_channels_eff, set_raw_counts\n",
    "from Optimization import Optimizer, function_fidelity, FidelityResults\n",
    "from constants import *\n",
    "\n",
    "from DensityMatrix import DensityMatrix, apply_unitary_to_dm\n",
    "\n",
    "from pathlib import Path\n",
    "import fnmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "######################################################################################################\n",
    "#----- COUNTING THE FILES AND SAVING THEM IN AN ARRAY TO MAKES THE REST OF THE ANALYSIS EASIER -------\n",
    "######################################################################################################\n",
    "\n",
    "n_files=0\n",
    "working_dir=r\"G:\\Other computers\\Mon ordinateur\\ChannelCertification\\SteeringHonest\"\n",
    "os.chdir(working_dir)\n",
    "\n",
    "filenames = [i for i in glob.glob(\"Channel*\")]\n",
    "filenames.sort(key=os.path.getmtime)\n",
    "\n",
    "index_to_file = {}\n",
    "\n",
    "for index, filename in enumerate(filenames):\n",
    "    os.chdir(f\"{working_dir}\\\\{filename}\")\n",
    "    filenames_aux=[i for i in glob.glob(\"StateTomography*\")]\n",
    "    for index_second, filenames_aux_second in enumerate(filenames_aux):\n",
    "        index_to_file[n_files] = f\"{filename}\\\\{filenames_aux_second}\"\n",
    "        n_files+=1\n",
    "os.chdir(working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.chdir(working_dir)\n",
    "qubit_number=2\n",
    "\n",
    "state_after=[]\n",
    "xp_counts_after_corrected_with_eff=[]\n",
    "state_after_file=[]\n",
    "\n",
    "state_before=[]\n",
    "xp_counts_before_corrected_with_eff=[]\n",
    "state_before_file=[]\n",
    "state = []\n",
    "xp_counts_corrected_with_eff=[]\n",
    "\n",
    "#####################################################################\n",
    "#---------------------- STATE TOMOGRAPHY ----------------------------\n",
    "#####################################################################\n",
    "\n",
    "for index in range(len(index_to_file)):\n",
    "    os.chdir(f\"{working_dir}\\\\{index_to_file[index]}\\\\StateTomo\")\n",
    "    datafiles=[i for i in glob.glob(\"*\")]\n",
    "                \n",
    "    ### Calculating the efficiencies of each detector\n",
    "    efficiencies=get_channels_eff(datafiles, os.getcwd())\n",
    "\n",
    "    ### Opening the data files and writing the data in counts_aux array\n",
    "    counts_aux=set_raw_counts(datafiles, qubit_number, os.getcwd())\n",
    "    xp_counts=np.array(np.transpose(counts_aux))\n",
    "\n",
    "    statetomo=LRETomography(int(qubit_number), xp_counts)\n",
    "    statetomo.run(correct_eff=efficiencies, print_nc=False)\n",
    "    xp_counts_corrected_with_eff.append(statetomo.xp_counts)\n",
    "\n",
    "    ## The 'e' and 'r' serve to distinguish between tomography before and after, respectively\n",
    "    ## We want to save them in different arrays because we need them for different things\n",
    "    if index_to_file[index][-8]=='e':\n",
    "        state_before.append(DensityMatrix(statetomo.quantum_state.get_density_matrix()))\n",
    "        xp_counts_before_corrected_with_eff.append(statetomo.xp_counts)\n",
    "        state_before_file.append(index_to_file[index])\n",
    "        #print('\\n Fast maximum likelihood estimation: \\n', state_before[-1], '\\n')\n",
    "\n",
    "    elif index_to_file[index][-8]=='r':\n",
    "        state_after.append(DensityMatrix(statetomo.quantum_state.get_density_matrix()))\n",
    "        xp_counts_after_corrected_with_eff.append(statetomo.xp_counts)\n",
    "        state_after_file.append(index_to_file[index])\n",
    "        #print('\\n Fast maximum likelihood estimation: \\n', state_after[-1], '\\n')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "#-- DEFINING THE TARGET BELL STATE ---\n",
    "######################################\n",
    "\n",
    "#bell=(np.array([1,0,0,0])+np.array([0,0,0,1]))/np.sqrt(2)\n",
    "#bell=(np.array([1,0,0,0])-np.array([0,0,0,1]))/np.sqrt(2)\n",
    "bell=(np.array([0,1,0,0])+np.array([0,0,1,0]))/np.sqrt(2)\n",
    "#bell=(np.array([0,1,0,0])-np.array([0,0,1,0]))/np.sqrt(2)\n",
    "bellmatrix=np.array(np.outer(bell, np.conjugate(bell)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# states=state_after\n",
    "# for index in range(len(states)):\n",
    "#     print(np.real(np.round(states[index].fidelity_to_pure(bell),5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0 has ChiSquare: -0.080570\n",
      "Generation 50 has ChiSquare: -0.994337\n",
      "Generation 100 has ChiSquare: -0.994337\n",
      "Generation 150 has ChiSquare: -0.994337\n",
      "STOP(\"ChangeOverGeneration with {'tolerance': 1e-08, 'generations': 100}\")\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.994337\n",
      "         Iterations: 183\n",
      "         Function evaluations: 18400\n",
      "Generation 0 has ChiSquare: -0.033834\n",
      "Generation 50 has ChiSquare: -0.991914\n",
      "Generation 100 has ChiSquare: -0.991920\n",
      "Generation 150 has ChiSquare: -0.991920\n",
      "Generation 200 has ChiSquare: -0.991920\n",
      "STOP(\"ChangeOverGeneration with {'tolerance': 1e-08, 'generations': 100}\")\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.991920\n",
      "         Iterations: 237\n",
      "         Function evaluations: 23800\n",
      "Generation 0 has ChiSquare: -0.011141\n",
      "Generation 50 has ChiSquare: -0.990963\n",
      "Generation 100 has ChiSquare: -0.990965\n",
      "Generation 150 has ChiSquare: -0.990965\n",
      "Generation 200 has ChiSquare: -0.990965\n",
      "STOP(\"ChangeOverGeneration with {'tolerance': 1e-08, 'generations': 100}\")\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.990965\n",
      "         Iterations: 201\n",
      "         Function evaluations: 20200\n",
      "Generation 0 has ChiSquare: -0.003300\n",
      "Generation 50 has ChiSquare: -0.992785\n",
      "Generation 100 has ChiSquare: -0.992793\n",
      "Generation 150 has ChiSquare: -0.992793\n",
      "Generation 200 has ChiSquare: -0.992793\n",
      "STOP(\"ChangeOverGeneration with {'tolerance': 1e-08, 'generations': 100}\")\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.992793\n",
      "         Iterations: 235\n",
      "         Function evaluations: 23600\n",
      "Generation 0 has ChiSquare: -0.004834\n",
      "Generation 50 has ChiSquare: -0.992399\n",
      "Generation 100 has ChiSquare: -0.992402\n",
      "Generation 150 has ChiSquare: -0.992402\n",
      "Generation 200 has ChiSquare: -0.992402\n",
      "STOP(\"ChangeOverGeneration with {'tolerance': 1e-08, 'generations': 100}\")\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.992402\n",
      "         Iterations: 228\n",
      "         Function evaluations: 22900\n",
      "Generation 0 has ChiSquare: -0.010840\n",
      "Generation 50 has ChiSquare: -0.991956\n",
      "Generation 100 has ChiSquare: -0.991979\n",
      "Generation 150 has ChiSquare: -0.991980\n",
      "Generation 200 has ChiSquare: -0.991980\n",
      "STOP(\"ChangeOverGeneration with {'tolerance': 1e-08, 'generations': 100}\")\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.991980\n",
      "         Iterations: 232\n",
      "         Function evaluations: 23300\n",
      "Generation 0 has ChiSquare: -0.012325\n",
      "Generation 50 has ChiSquare: -0.993393\n",
      "Generation 100 has ChiSquare: -0.993395\n",
      "Generation 150 has ChiSquare: -0.993395\n",
      "Generation 200 has ChiSquare: -0.993395\n",
      "STOP(\"ChangeOverGeneration with {'tolerance': 1e-08, 'generations': 100}\")\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.993395\n",
      "         Iterations: 226\n",
      "         Function evaluations: 22700\n",
      "Generation 0 has ChiSquare: -0.024791\n",
      "Generation 50 has ChiSquare: -0.993530\n",
      "Generation 100 has ChiSquare: -0.993534\n",
      "Generation 150 has ChiSquare: -0.993534\n",
      "Generation 200 has ChiSquare: -0.993534\n",
      "Generation 250 has ChiSquare: -0.993534\n",
      "STOP(\"ChangeOverGeneration with {'tolerance': 1e-08, 'generations': 100}\")\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.993534\n",
      "         Iterations: 262\n",
      "         Function evaluations: 26300\n",
      "Generation 0 has ChiSquare: -0.030500\n",
      "Generation 50 has ChiSquare: -0.992798\n",
      "Generation 100 has ChiSquare: -0.992813\n",
      "Generation 150 has ChiSquare: -0.992813\n",
      "STOP(\"ChangeOverGeneration with {'tolerance': 1e-08, 'generations': 100}\")\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.992813\n",
      "         Iterations: 191\n",
      "         Function evaluations: 19200\n",
      "Generation 0 has ChiSquare: -0.072159\n",
      "Generation 50 has ChiSquare: -0.993033\n",
      "Generation 100 has ChiSquare: -0.993044\n",
      "Generation 150 has ChiSquare: -0.993044\n",
      "Generation 200 has ChiSquare: -0.993044\n",
      "Generation 250 has ChiSquare: -0.993044\n",
      "STOP(\"ChangeOverGeneration with {'tolerance': 1e-08, 'generations': 100}\")\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.993044\n",
      "         Iterations: 258\n",
      "         Function evaluations: 25900\n",
      "Generation 0 has ChiSquare: -0.008428\n",
      "Generation 50 has ChiSquare: -0.990916\n",
      "Generation 100 has ChiSquare: -0.990923\n",
      "Generation 150 has ChiSquare: -0.990923\n",
      "Generation 200 has ChiSquare: -0.990923\n",
      "STOP(\"ChangeOverGeneration with {'tolerance': 1e-08, 'generations': 100}\")\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.990923\n",
      "         Iterations: 244\n",
      "         Function evaluations: 24500\n",
      "Generation 0 has ChiSquare: -0.021315\n",
      "Generation 50 has ChiSquare: -0.983666\n",
      "Generation 100 has ChiSquare: -0.983673\n",
      "Generation 150 has ChiSquare: -0.983673\n",
      "Generation 200 has ChiSquare: -0.983673\n",
      "STOP(\"ChangeOverGeneration with {'tolerance': 1e-08, 'generations': 100}\")\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.983673\n",
      "         Iterations: 220\n",
      "         Function evaluations: 22100\n"
     ]
    }
   ],
   "source": [
    "##########################################################\n",
    "#----- OPTIMIZATION OF MAX FIDELITY UP TO UNITARIES ------\n",
    "##########################################################\n",
    "bell=(np.array([0,1,0,0])+np.array([0,0,1,0]))/np.sqrt(2)\n",
    "fid=np.zeros((n_files))\n",
    "optimized_matrix=np.zeros((n_files,2**qubit_number,2**qubit_number), dtype='complex')\n",
    "\n",
    "guess=np.array([0, 0, 0, 0, 0, 0])\n",
    "bounds=[(-np.pi,np.pi)]*6\n",
    "results = []\n",
    "\n",
    "opt=Optimizer(guess, function_fidelity, results=FidelityResults)\n",
    "\n",
    "for index in range(len(state_before)):\n",
    "    result=opt.optimize(state_before[index], bell, bounds=bounds)\n",
    "    results.append(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index, fidelity, fidelity_mean, fidelity_std:  0 (0.99274+0j) 0.85489 0.00085\n",
      "index, fidelity, fidelity_mean, fidelity_std:  1 (0.99921-0j) 0.95899 0.00059\n",
      "index, fidelity, fidelity_mean, fidelity_std:  2 (0.01348-0j) 0.0141 0.00041\n",
      "index, fidelity, fidelity_mean, fidelity_std:  3 (0.99464-0j) 0.98491 0.00029\n",
      "index, fidelity, fidelity_mean, fidelity_std:  4 (0.99478+0j) 0.98223 0.00036\n",
      "index, fidelity, fidelity_mean, fidelity_std:  5 (0.98964-0j) 0.96659 0.00053\n",
      "index, fidelity, fidelity_mean, fidelity_std:  6 (0.99193+0j) 0.96272 0.00052\n",
      "index, fidelity, fidelity_mean, fidelity_std:  7 (0.99621+0j) 0.90784 0.00051\n",
      "index, fidelity, fidelity_mean, fidelity_std:  8 (0.9964+0j) 0.9 0.00041\n",
      "index, fidelity, fidelity_mean, fidelity_std:  9 (0.99564+0j) 0.82788 0.00063\n",
      "index, fidelity, fidelity_mean, fidelity_std:  10 (0.99365+0j) 0.97794 0.00054\n",
      "index, fidelity, fidelity_mean, fidelity_std:  11 (0.9862-0j) 0.94602 0.00066\n"
     ]
    }
   ],
   "source": [
    "##########################################################\n",
    "#---------------- CALCULATING THE ERRORS -----------------\n",
    "##########################################################\n",
    "bell=(np.array([0,1,0,0])+np.array([0,0,1,0]))/np.sqrt(2)\n",
    "error_runs=1000\n",
    "\n",
    "mu=np.zeros((n_files))\n",
    "std=np.zeros((n_files))\n",
    "\n",
    "U=[]\n",
    "bell_aux=[]\n",
    "target=[]\n",
    "states_final=[]\n",
    "\n",
    "states=state_before #[DensityMatrix(x.optimized_state) for x in results] #\n",
    "xp_counts_corrected_with_eff=xp_counts_before_corrected_with_eff\n",
    "\n",
    "for index in range(len(states)):\n",
    "    \n",
    "    #bell_aux is the state after applying the inverse of the unitaries found in the optimization\n",
    "    U.append(np.kron(results[index].u1,results[index].u2))\n",
    "    target.append(np.linalg.inv(U[-1])@state_after[index].state@np.linalg.inv(np.transpose(np.conjugate(U[-1]))))\n",
    "    #bell_aux.append(np.conjugate(np.transpose(U))@bell)\n",
    "    \n",
    "    dm = states[index]#.optimizedapply_unitary(U[-1])\n",
    "    dm.calculate_errors(xp_counts_corrected_with_eff[index].counts_array, error_runs, target[-1])\n",
    "    states_final.append(dm)\n",
    "    \n",
    "    print('index, fidelity, fidelity_mean, fidelity_std: ',\n",
    "          index, np.round(states_final[-1].fidelity(target[-1]),5), np.round(states_final[-1].mu,5),\n",
    "          np.round(states_final[-1].std,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0 has ChiSquare: -0.003392\n",
      "Generation 50 has ChiSquare: -0.990965\n",
      "Generation 100 has ChiSquare: -0.990965\n",
      "Generation 150 has ChiSquare: -0.990965\n",
      "STOP(\"ChangeOverGeneration with {'tolerance': 1e-08, 'generations': 100}\")\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.990965\n",
      "         Iterations: 180\n",
      "         Function evaluations: 18100\n",
      "index, fidelity, fidelity_mean, fidelity_std:  11 (0.99632+0j) 0.99364 0.00081\n"
     ]
    }
   ],
   "source": [
    "bell=(np.array([0,1,0,0])-np.array([0,0,1,0]))/np.sqrt(2)\n",
    "bellmatrix=np.array(np.outer(bell, np.conjugate(bell)))\n",
    "\n",
    "result=opt.optimize(state_before[2], bell, bounds=bounds)\n",
    "U[2]=np.kron(result.u1,result.u2)\n",
    "target[2]=np.linalg.inv(U[2])@state_after[2].state@np.linalg.inv(np.transpose(np.conjugate(U[2])))\n",
    "\n",
    "dm = states[2]\n",
    "dm.calculate_errors(xp_counts_corrected_with_eff[2].counts_array, error_runs, target[2])\n",
    "states_final[2]=dm\n",
    "\n",
    "print('index, fidelity, fidelity_mean, fidelity_std: ',\n",
    "          index, np.round(states_final[2].fidelity(target[2]),5), np.round(states_final[2].mu,5),\n",
    "          np.round(states_final[2].std,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#------------ WRITING THE DATA IN AN EXCEL ---------------\n",
    "##########################################################\n",
    "\n",
    "import xlsxwriter\n",
    "states=state_before\n",
    "\n",
    "workbook = xlsxwriter.Workbook('fidelities_to_ini_state_errors.xlsx') ### We should write this in another place\n",
    " \n",
    "worksheet = workbook.add_worksheet()\n",
    "\n",
    "worksheet.write('A1', 'Number')\n",
    "worksheet.write('B1', 'Folder')\n",
    "worksheet.write('C1', 'Fidelity')\n",
    "worksheet.write('D1', 'Fidelity_mean')\n",
    "worksheet.write('E1', 'Fidelity_uncertainty')\n",
    "\n",
    "counter=0\n",
    "for index in range(len(state_before)):\n",
    "    \n",
    "    worksheet.write('A'+str(counter+2), counter)\n",
    "    worksheet.write('B'+str(counter+2), state_before_file[index])\n",
    "    worksheet.write('C'+str(counter+2), np.real(np.round(states_final[index].fidelity(target[index]),5)))#np.round(states[index].fidelity_to_pure(bell),5)))\n",
    "    worksheet.write('D'+str(counter+2), np.real(np.round(states_final[index].mu,5)))\n",
    "    worksheet.write('E'+str(counter+2), np.real(np.round(states_final[index].std,5)))\n",
    "    counter+=1\n",
    "        \n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IF WE WANT TO CHECK THE FIT TO THE UNCERTARTAINTY\n",
    "### Then we need to calculate the statistic on these simulated fidelities and calculate the standart deviation\n",
    "### This will be our uncertainty due to statistical errors\n",
    "def count_elements(seq) -> dict:\n",
    "    hist = {}\n",
    "    for i in seq:\n",
    "        hist[i] = hist.get(i, 0) + 1\n",
    "    return hist\n",
    "\n",
    "counted = count_elements(fidelity_sim)\n",
    "#print(counted)\n",
    "bin_numb = len(counted)\n",
    "errorbar_x=np.array(list(counted))\n",
    "errorbar_y=np.zeros((bin_numb), dtype=int)\n",
    "\n",
    "for i in range(bin_numb):\n",
    "    errorbar_y[i]=counted[errorbar_x[i]]\n",
    "    \n",
    "#print(errorbar_x)\n",
    "#print(errorbar_y)\n",
    "    \n",
    "def Gauss(x, A, mu, sigm):\n",
    "    y = A*np.exp(-((x-mu)/sigm)**2/2)\n",
    "    return y\n",
    "\n",
    "mu, std = norm.fit(fidelity_sim)\n",
    "print(mu, std)\n",
    "parameters, covariance = curve_fit(Gauss, xdata=errorbar_x[-1], ydata=errorbar_y[:-1], bounds=[(0,0.99007,1e-4),(60,0.9903,0.0002)])\n",
    "fit_A = parameters[0]\n",
    "fit_B = parameters[1]\n",
    "fit_C = parameters[2]\n",
    "print(fit_A, fit_B, fit_C)\n",
    "\n",
    "xdata= x = np.linspace(0.989, 0.991, 100)\n",
    "fit_y = Gauss(xdata, fit_A, fit_B, fit_C)\n",
    "plt.plot(errorbar_x[:-1], errorbar_y[:-1], 'o', label='data')\n",
    "plt.plot(xdata, fit_y, '-', label='fit')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
