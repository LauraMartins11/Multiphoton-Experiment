{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import time\n",
    "import math\n",
    "from scipy.stats import norm\n",
    "\n",
    "import mystic\n",
    "from mystic.solvers import DifferentialEvolutionSolver, diffev2\n",
    "from mystic.strategy import Best1Bin\n",
    "from mystic.monitors import Monitor,VerboseMonitor\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from tomography import *\n",
    "\n",
    "from NestedForLoop import get_iterator\n",
    "from pathlib import Path\n",
    "from scipy.linalg import sqrtm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.optimize import least_squares\n",
    "\n",
    "import fnmatch\n",
    "from efficiencies import finding_file, get_channels_eff, set_raw_counts\n",
    "from optimization import Optimizer, function_fidelity, FidelityResults\n",
    "from constants import *\n",
    "\n",
    "from densitymatrix import DensityMatrix, apply_unitary_to_dm\n",
    "\n",
    "from pathlib import Path\n",
    "import fnmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = os.getcwd()\n",
    "working_dir_data = os.getcwd()+'\\StateTomoData'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "######################################################################################################\n",
    "#----- COUNTING THE FILES AND SAVING THEM IN AN ARRAY TO MAKES THE REST OF THE ANALYSIS EASIER -------\n",
    "######################################################################################################\n",
    "\n",
    "n_files=0\n",
    "os.chdir(working_dir_data)\n",
    "\n",
    "filenames = [i for i in glob.glob(\"StateTomo_2Layers*\")]\n",
    "filenames.sort(key=os.path.getmtime)\n",
    "\n",
    "index_to_file = {}\n",
    "\n",
    "for index, filename in enumerate(filenames):\n",
    "    os.chdir(f\"{working_dir_data}\\\\{filename}\")\n",
    "    filenames_aux=[i for i in glob.glob(\"StateTomo*\")]\n",
    "    for index_second, filenames_aux_second in enumerate(filenames_aux):\n",
    "        index_to_file[n_files] = f\"{filename}\\\\{filenames_aux_second}\"\n",
    "        n_files+=1\n",
    "os.chdir(working_dir)\n",
    "# print(filenames_aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j\n",
      "   0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j]\n",
      "  [0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j\n",
      "   0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j]\n",
      "  [0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j\n",
      "   0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j]\n",
      "  [0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j\n",
      "   0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j]]\n",
      "\n",
      " [[0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j\n",
      "   0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j]\n",
      "  [0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j\n",
      "   0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j]\n",
      "  [0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j\n",
      "   0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j]\n",
      "  [0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j\n",
      "   0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j]]\n",
      "\n",
      " [[0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j\n",
      "   0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j]\n",
      "  [0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j\n",
      "   0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j]\n",
      "  [0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j\n",
      "   0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j]\n",
      "  [0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j\n",
      "   0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j]]\n",
      "\n",
      " [[0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j\n",
      "   0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j]\n",
      "  [0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j\n",
      "   0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j]\n",
      "  [0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j\n",
      "   0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j]\n",
      "  [0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j\n",
      "   0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j]]\n",
      "\n",
      " [[0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j\n",
      "   0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j]\n",
      "  [0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j\n",
      "   0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j]\n",
      "  [0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j\n",
      "   0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j]\n",
      "  [0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j\n",
      "   0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j]]\n",
      "\n",
      " [[0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j\n",
      "   0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j]\n",
      "  [0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j\n",
      "   0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j]\n",
      "  [0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j\n",
      "   0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j]\n",
      "  [0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j\n",
      "   0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j]]\n",
      "\n",
      " [[0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j\n",
      "   0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j]\n",
      "  [0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j\n",
      "   0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j]\n",
      "  [0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j\n",
      "   0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j]\n",
      "  [0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j\n",
      "   0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j]]\n",
      "\n",
      " [[0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j\n",
      "   0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j]\n",
      "  [0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j\n",
      "   0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j]\n",
      "  [0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j\n",
      "   0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j]\n",
      "  [0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j\n",
      "   0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j]]\n",
      "\n",
      " [[0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j\n",
      "   0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j]\n",
      "  [0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j\n",
      "   0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j]\n",
      "  [0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j\n",
      "   0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j]\n",
      "  [0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j\n",
      "   0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j]]]\n"
     ]
    }
   ],
   "source": [
    "m=np.load(working_dir+'\\SavedVariables\\X_matrix2.npy')\n",
    "n=np.load(working_dir+'\\SavedVariables\\X_matrix2trial.npy')\n",
    "print(np.round(m-n,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(working_dir)\n",
    "qubit_number=2\n",
    "\n",
    "## Defining the columns of the data file we want to use as data to reconstruct the density matrix (eg.: HH HV VH and VV basis)\n",
    "column_start=12\n",
    "column_stop=16\n",
    "\n",
    "column_start_2_emissions=21\n",
    "column_stop_2_emissions=25\n",
    "\n",
    "state_after=[]\n",
    "state_after_file=[]\n",
    "\n",
    "state_before=[]\n",
    "state_before_file=[]\n",
    "\n",
    "state = []\n",
    "state_file=[]\n",
    "\n",
    "xp_counts_corrected_with_eff=[]\n",
    "\n",
    "statetomo = []\n",
    "\n",
    "#####################################################################\n",
    "#---------------------- STATE TOMOGRAPHY ----------------------------\n",
    "#####################################################################\n",
    "for index in range(len(index_to_file)):\n",
    "    os.chdir(f\"{working_dir_data}\\\\{index_to_file[index]}\\\\\")\n",
    "    datafiles=[i for i in glob.glob(\"*\")]\n",
    "                \n",
    "    ### Calculating the efficiencies of each detector\n",
    "    efficiencies=get_channels_eff(datafiles, column_start, column_stop, os.getcwd())\n",
    "    efficiencies_2_emissions=get_channels_eff(datafiles, column_start_2_emissions, column_stop_2_emissions, os.getcwd())\n",
    "\n",
    "\n",
    "    ### Opening the data files and writing the data in counts_aux array\n",
    "    counts_aux=set_raw_counts(datafiles, qubit_number, column_start, column_stop, os.getcwd())\n",
    "    xp_counts=np.array(np.transpose(counts_aux))\n",
    " \n",
    "    counts_aux_2_emissions=set_raw_counts(datafiles, qubit_number, column_start_2_emissions, column_stop_2_emissions, os.getcwd())\n",
    "    xp_counts_2_emissions=np.array(np.transpose(counts_aux_2_emissions))\n",
    "\n",
    "    statetomo.append(LRETomography(int(qubit_number),xp_counts, xp_counts_2_emissions))\n",
    "    statetomo[-1].run(correct_eff=efficiencies)\n",
    "    xp_counts_corrected_with_eff.append(statetomo[-1].xp_counts)\n",
    "\n",
    "    ## The 'e' and 'r' serve to distinguish between tomography before and after, respectively\n",
    "    ## We want to save them in different arrays because we need them for different things\n",
    "#     elif index_to_file[index][-8]=='e':\n",
    "#         state_before.append(statetomo[-1])#.state)\n",
    "#         state_before_file.append(index_to_file[index])\n",
    "#         #print('\\n Fast maximum likelihood estimation: \\n', state_before[-1], '\\n')\n",
    "\n",
    "#     elif index_to_file[index][-8]=='r':\n",
    "#         state_after.append(statetomo[-1])#.state)\n",
    "#         state_after_file.append(index_to_file[index])\n",
    "#         #print('\\n Fast maximum likelihood estimation: \\n', state_after[-1], '\\n')\n",
    "        \n",
    "    state.append(statetomo[-1])#.state)\n",
    "    state_file.append(index_to_file[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# states=state\n",
    "# for index in range(len(states)):\n",
    "#     print(np.real(np.round(states[index].state.fidelity(bell),5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "#-- DEFINING THE TARGET BELL STATE ---\n",
    "######################################\n",
    "\n",
    "# bell=(np.array([1,0,0,0])+np.array([0,0,0,1]h))/np.sqrt(2)\n",
    "bell=(np.array([1,0,0,0])-np.array([0,0,0,1]))/np.sqrt(2)\n",
    "# bell=(np.array([0,1,0,0])+np.array([0,0,1,0]))/np.sqrt(2)\n",
    "# bell=(np.array([0,1,0,0])-np.array([0,0,1,0]))/np.sqrt(2)\n",
    "bellmatrix=np.array(np.outer(bell, np.conjugate(bell)))\n",
    "\n",
    "##########################################################\n",
    "#----- OPTIMIZATION OF MAX FIDELITY UP TO UNITARIES ------\n",
    "##########################################################\n",
    "states=state\n",
    "fid=np.zeros((n_files))\n",
    "optimized_matrix=np.zeros((n_files,2**qubit_number,2**qubit_number), dtype='complex')\n",
    "\n",
    "guess=np.array([0, 0, 0])\n",
    "bounds=[(-np.pi,np.pi)]*3\n",
    "results = []\n",
    "\n",
    "opt=Optimizer(guess, function_fidelity, results=FidelityResults)\n",
    "\n",
    "for index in range(len(states)):\n",
    "    result=opt.optimize(states[index].state, bell, bounds=bounds)\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating new states considering the uncertainties\n",
      "Optimizing the fidelity between input and target up to a unitary\n",
      "file, fidelity, fidelity_mean, fidelity_std:  StateTomo_2Layers\\StateTomography_20230504 (0.98699+0j) 0.98707 0.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "##########################################################\n",
    "#------------ ERRORS Input with BELL STATE---------------#\n",
    "##########################################################\n",
    "error_runs=1\n",
    "\n",
    "U=[]\n",
    "bell_aux=[]\n",
    "target_ini=[]\n",
    "\n",
    "states=state\n",
    "states_file=state_file\n",
    "players=[\"Cersei\", \"Dany\"]\n",
    "\n",
    "for index in range(len(states)):\n",
    "    target=bellmatrix\n",
    "    U.append(results[index].u)\n",
    "    target_ini.append(np.transpose(np.conjugate(U[-1]))@bellmatrix@U[-1])    \n",
    "    \n",
    "    states[index].calculate_fidelity_error(players, error_runs, opt, target, optimization=True, bounds=bounds)\n",
    "    \n",
    "    print('file, fidelity, fidelity_mean, fidelity_std: ',\n",
    "          states_file[index], np.round(states[index].state.fidelity(target_ini[-1]),5), -np.round(states[index].fidelity_mu,5),\n",
    "          np.round(states[index].fidelity_std,5), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#--------------- ERRORS OUTPUT TO INTPUT ----------------#\n",
    "##########################################################\n",
    "U=[]\n",
    "bell_aux=[]\n",
    "target_ini=[]\n",
    "\n",
    "states=state_before\n",
    "\n",
    "for index in range(len(states)):\n",
    "    target=state_after[index]\n",
    "    U.append(np.kron(results[index].u1,results[index].u2))\n",
    "    target_ini.append(np.transpose(np.conjugate(U[-1]))@state_after[index].state.state@U[-1])\n",
    "    \n",
    "    states[index].calculate_fidelity_error_between_2_experimental_matrices(error_runs, players, target, apply_unitary_to_input=True)\n",
    "    \n",
    "    print('file, fidelity, fidelity_mean, fidelity_std: ',\n",
    "          state_after_file[index], np.round(states[index].state.fidelity(target_ini[-1]),5), -np.round(states[index].fidelity_2_experimental_dms_mu,5),\n",
    "          np.round(states[index].fidelity_2_experimental_dms_std,5), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24660\\1580401616.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mbellmatrix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mouter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbell\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconjugate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mresult\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_before\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbell\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbounds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mU\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkron\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mu1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mu2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "bell=(np.array([0,1,0,0])-np.array([0,0,1,0]))/np.sqrt(2)\n",
    "bellmatrix=np.array(np.outer(bell, np.conjugate(bell)))\n",
    "\n",
    "result=opt.optimize(state_before[2].state, bell, bounds=bounds)\n",
    "U[2]=np.kron(result.u1,result.u2)\n",
    "\n",
    "t=state_after[2].state.state\n",
    "\n",
    "t_ini=np.linalg.inv(U[2])@state_after[2].state.state@np.linalg.inv(np.transpose(np.conjugate(U[2])))\n",
    "\n",
    "states[2].calculate_fidelity_error(players, error_runs, opt, t, bounds=bounds)\n",
    "\n",
    "print('index, fidelity, fidelity_mean, fidelity_std: ',\n",
    "        state_before_file[index], np.round(states[2].state.fidelity(t_ini),5), np.round(states[2].fidelity_mu,5),\n",
    "        np.round(states[2].fidelity_std,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#------------ ERRORS OUTPUT with BELL STATE--------------#\n",
    "##########################################################\n",
    "bell=(np.array([0,1,0,0])+np.array([0,0,1,0]))/np.sqrt(2)\n",
    "bellmatrix=np.array(np.outer(bell, np.conjugate(bell)))\n",
    "error_runs=30\n",
    "\n",
    "U=[]\n",
    "bell_aux=[]\n",
    "target_ini=[]\n",
    "\n",
    "states=state_after\n",
    "players=[\"Arya\", \"Cersei\"]\n",
    "\n",
    "guess=np.array([0, 0, 0])\n",
    "bounds=[(-np.pi,np.pi)]*3\n",
    "opt=Optimizer(guess, function_fidelity, results=FidelityResults)\n",
    "\n",
    "for index in range(len(states)):\n",
    "    target=bellmatrix\n",
    "    #U.append(results[index].u)\n",
    "    #target_ini.append(np.transpose(np.conjugate(U[-1]))@bellmatrix@U[-1])    \n",
    "    \n",
    "    states[index].calculate_fidelity_error(players, error_runs, opt, target, bounds=bounds)\n",
    "    \n",
    "    print('index, fidelity, fidelity_mean, fidelity_std: ',\n",
    "          state_after_file[index], np.round(states[index].state.fidelity(target),5), np.round(states[index].fidelity_mu,5),\n",
    "          np.round(states[index].fidelity_std,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bell=(np.array([0,1,0,0])-np.array([0,0,1,0]))/np.sqrt(2)\n",
    "bellmatrix=np.array(np.outer(bell, np.conjugate(bell)))\n",
    "target=bellmatrix\n",
    "\n",
    "result=opt.optimize(state_before[2].state, bell, bounds=bounds)\n",
    "\n",
    "t=state_after[2].state.state\n",
    "\n",
    "states[2].calculate_fidelity_error(players, error_runs, opt, t, bounds=bounds)\n",
    "\n",
    "print('index, fidelity, fidelity_mean, fidelity_std: ',\n",
    "        state_after_file[index], np.round(states[2].state.fidelity(target),5), np.round(states[2].fidelity_mu,5),\n",
    "        np.round(states[2].fidelity_std,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#------------ WRITING THE DATA IN AN EXCEL ---------------\n",
    "##########################################################\n",
    "\n",
    "import xlsxwriter\n",
    "states=state_before\n",
    "\n",
    "workbook = xlsxwriter.Workbook('fidelities_to_ini_state_errors.xlsx') ### We should write this in another place\n",
    " \n",
    "worksheet = workbook.add_worksheet()\n",
    "\n",
    "worksheet.write('A1', 'Number')\n",
    "worksheet.write('B1', 'Folder')\n",
    "worksheet.write('C1', 'Fidelity')\n",
    "worksheet.write('D1', 'Fidelity_mean')\n",
    "worksheet.write('E1', 'Fidelity_uncertainty')\n",
    "\n",
    "counter=0\n",
    "for index in range(len(state_before)):\n",
    "    \n",
    "    worksheet.write('A'+str(counter+2), counter)\n",
    "    worksheet.write('B'+str(counter+2), state_before_file[index])\n",
    "    worksheet.write('C'+str(counter+2), np.real(np.round(states_final[index].fidelity(target[index]),5)))#np.round(states[index].fidelity_to_pure(bell),5)))\n",
    "    worksheet.write('D'+str(counter+2), np.real(np.round(states_final[index].mu,5)))\n",
    "    worksheet.write('E'+str(counter+2), np.real(np.round(states_final[index].std,5)))\n",
    "    counter+=1\n",
    "        \n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IF WE WANT TO CHECK THE FIT TO THE UNCERTARTAINTY\n",
    "### Then we need to calculate the statistic on these simulated fidelities and calculate the standart deviation\n",
    "### This will be our uncertainty due to statistical errors\n",
    "def count_elements(seq) -> dict:\n",
    "    hist = {}\n",
    "    for i in seq:\n",
    "        hist[i] = hist.get(i, 0) + 1\n",
    "    return hist\n",
    "\n",
    "counted = count_elements(fidelity_sim)\n",
    "#print(counted)\n",
    "bin_numb = len(counted)\n",
    "errorbar_x=np.array(list(counted))\n",
    "errorbar_y=np.zeros((bin_numb), dtype=int)\n",
    "\n",
    "for i in range(bin_numb):\n",
    "    errorbar_y[i]=counted[errorbar_x[i]]\n",
    "    \n",
    "#print(errorbar_x)\n",
    "#print(errorbar_y)\n",
    "    \n",
    "def Gauss(x, A, mu, sigm):\n",
    "    y = A*np.exp(-((x-mu)/sigm)**2/2)\n",
    "    return y\n",
    "\n",
    "mu, std = norm.fit(fidelity_sim)\n",
    "print(mu, std)\n",
    "parameters, covariance = curve_fit(Gauss, xdata=errorbar_x[-1], ydata=errorbar_y[:-1], bounds=[(0,0.99007,1e-4),(60,0.9903,0.0002)])\n",
    "fit_A = parameters[0]\n",
    "fit_B = parameters[1]\n",
    "fit_C = parameters[2]\n",
    "print(fit_A, fit_B, fit_C)\n",
    "\n",
    "xdata= x = np.linspace(0.989, 0.991, 100)\n",
    "fit_y = Gauss(xdata, fit_A, fit_B, fit_C)\n",
    "plt.plot(errorbar_x[:-1], errorbar_y[:-1], 'o', label='data')\n",
    "plt.plot(xdata, fit_y, '-', label='fit')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
