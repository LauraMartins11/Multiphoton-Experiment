{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import time\n",
    "import math\n",
    "import itertools\n",
    "from scipy.stats import norm\n",
    "\n",
    "import mystic\n",
    "from mystic.solvers import DifferentialEvolutionSolver, diffev2\n",
    "from mystic.strategy import Best1Bin\n",
    "from mystic.monitors import Monitor,VerboseMonitor\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from tomography import *\n",
    "\n",
    "from NestedForLoop import get_iterator\n",
    "from pathlib import Path\n",
    "from scipy.linalg import sqrtm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.optimize import least_squares\n",
    "\n",
    "import fnmatch\n",
    "from efficiencies import finding_file, get_channels_eff, set_raw_counts\n",
    "from optimization import Optimizer, function_fidelity, FidelityResults\n",
    "from constants import *\n",
    "\n",
    "from densitymatrix import DensityMatrix, apply_unitary_to_dm\n",
    "\n",
    "from pathlib import Path\n",
    "import fnmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = os.getcwd()\n",
    "working_dir_data = os.getcwd()+'\\StateTomoData'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyse Files:  ['GHZ']\n"
     ]
    }
   ],
   "source": [
    "######################################################################################################\n",
    "#----- COUNTING THE FILES AND SAVING THEM IN AN ARRAY TO MAKES THE REST OF THE ANALYSIS EASIER -------\n",
    "######################################################################################################\n",
    "\n",
    "n_files=0\n",
    "os.chdir(working_dir_data)\n",
    "\n",
    "filenames = [i for i in glob.glob(\"Simulated*\")]\n",
    "filenames.sort(key=os.path.getmtime)\n",
    "\n",
    "index_to_file = {}\n",
    "\n",
    "for index, filename in enumerate(filenames):\n",
    "    os.chdir(f\"{working_dir_data}\\\\{filename}\")\n",
    "    filenames_aux=[i for i in glob.glob(\"GHZ*\")]\n",
    "    for index_second, filenames_aux_second in enumerate(filenames_aux):\n",
    "        index_to_file[n_files] = f\"{filename}\\\\{filenames_aux_second}\"\n",
    "        n_files+=1\n",
    "os.chdir(working_dir)\n",
    "print(\"Analyse Files: \", filenames_aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "#---------------------- DEFINING PARAMS ----------------------------#\n",
    "#####################################################################\n",
    "os.chdir(working_dir)\n",
    "qubit_number=4\n",
    "\n",
    "## Defining the columns of the data file we want to use as data to reconstruct the density matrix (eg.: HH HV VH and VV basis)\n",
    "BASIS_TO_CHANNEL={\n",
    "    \"HA\": 1,\n",
    "    \"VA\": 2,\n",
    "    \"HB\": 3,\n",
    "    \"VB\": 4,\n",
    "    \"HC\": 5,\n",
    "    \"VC\": 6,\n",
    "    \"HD\": 7,\n",
    "    \"VD\": 8,\n",
    "    }\n",
    "\n",
    "### Bell state ###\n",
    "# eigenstates = [['HA','HB'],['HA','VB'],['VA','HB'],['VA','VB']]\n",
    "\n",
    "### 4 qubits GHZ ###\n",
    "eigenstates = [['HA','HB','HC','HD'],['HA','HB','HC','VD'],['HA','HB','VC','HD'],['HA','HB','VC','VD'],\n",
    "               ['HA','VB','HC','HD'],['HA','VB','HC','VD'],['HA','VB','VC','HD'],['HA','VB','VC','VD'],\n",
    "               ['VA','HB','HC','HD'],['VA','HB','HC','VD'],['VA','HB','VC','HD'],['VA','HB','VC','VD'],\n",
    "               ['VA','VB','HC','HD'],['VA','VB','HC','VD'],['VA','VB','VC','HD'],['VA','VB','VC','VD']]\n",
    "\n",
    "fold = four_fold=[[BASIS_TO_CHANNEL[eigenstates[i][j]] for j in range(qubit_number)] for i in range(len(eigenstates))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile_channels = fold.copy()\n",
    "\n",
    "for clicks in fold:\n",
    "    not_in_clicks = list(set(range(1, 2*qubit_number+1)) - set(clicks))\n",
    "    not_in_clicks.sort()\n",
    "    for rep in range(1, len(not_in_clicks)+1):\n",
    "        for combo in itertools.combinations(not_in_clicks, rep):\n",
    "            new_clicks = clicks + list(combo)\n",
    "            new_clicks.sort()\n",
    "            datafile_channels.append(new_clicks)\n",
    "            \n",
    "datafile_channels = np.array(list(set(map(tuple, datafile_channels))), dtype=object)\n",
    "first_order = list(map(len, datafile_channels)) \n",
    "order = np.lexsort((datafile_channels, first_order))\n",
    "datafile_channels = list(datafile_channels[order])\n",
    "datafile_channels = [list(t) for t in datafile_channels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(datafile_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coincidences column_start: 0 ; column_stop:  16\n",
      "Double emission column_start: 16 ; column_stop:  80\n"
     ]
    }
   ],
   "source": [
    "single_channels_offset = 8\n",
    "coincidences_columns = []\n",
    "double_emission_columns = []\n",
    "\n",
    "for i, iter in enumerate(eigenstates):\n",
    "    proj = [BASIS_TO_CHANNEL[iter[m]] for m in range(qubit_number)]\n",
    "    coincidences_columns.append(datafile_channels.index(proj))\n",
    "    double_emission_columns.append([datafile_channels.index(d) for d in datafile_channels if set(proj).issubset(set(d))])\n",
    "    double_emission_columns[-1].remove(coincidences_columns[-1])\n",
    "\n",
    "column_start = np.min(coincidences_columns)# + single_channels_offset\n",
    "column_stop = np.max(coincidences_columns) + 1# + single_channels_offset\n",
    "print(\"Coincidences column_start:\", column_start,\"; column_stop: \", column_stop)\n",
    "\n",
    "column_start_2_emissions = np.min(double_emission_columns)# + single_channels_offset + 4\n",
    "column_stop_2_emissions = np.max(double_emission_columns)# + single_channels_offset + 4\n",
    "print(\"Double emission column_start:\", column_start_2_emissions, \"; column_stop: \", column_stop_2_emissions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels efficiencies:  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "statetomo = []\n",
    "state = []\n",
    "state_file = []\n",
    "\n",
    "xp_counts_corrected_with_eff=[]\n",
    "\n",
    "#####################################################################\n",
    "#---------------------- STATE TOMOGRAPHY ----------------------------\n",
    "#####################################################################\n",
    "for index in range(len(index_to_file)):\n",
    "    os.chdir(f\"{working_dir_data}\\\\{index_to_file[index]}\\\\\")\n",
    "    datafiles=[i for i in glob.glob(\"*\")]\n",
    "    \n",
    "    ### Calculating the efficiencies of each detector\n",
    "    efficiencies=get_channels_eff(datafiles, qubit_number, column_start, column_stop, os.getcwd())\n",
    "#     efficiencies_2_emissions=get_channels_eff(datafiles, qubit_number, column_start_2_emissions, column_stop_2_emissions, os.getcwd())\n",
    "    print(\"Channels efficiencies: \", efficiencies)\n",
    "#     print(\"Channels efficiencies (double emission): \", efficiencies_2_emissions)\n",
    "\n",
    "    ### Opening the data files and writing the data in counts_aux array\n",
    "    counts_aux=set_raw_counts(datafiles, qubit_number, column_start, column_stop, os.getcwd())\n",
    "    xp_counts=np.array(np.transpose(counts_aux))\n",
    "\n",
    "    counts_aux_2_emissions=set_raw_counts(datafiles, qubit_number, column_start_2_emissions, column_stop_2_emissions, os.getcwd())\n",
    "    xp_counts_2_emissions=np.array(np.transpose(counts_aux_2_emissions))\n",
    "\n",
    "    statetomo.append(LRETomography(int(qubit_number), xp_counts, xp_counts_2_emissions))\n",
    "    statetomo[-1].run(correct_eff=efficiencies, correct_double_emission_eff=None, correct_double_emission=double_emission_columns)\n",
    "    xp_counts_corrected_with_eff.append(statetomo[-1].xp_counts)\n",
    "        \n",
    "    state.append(statetomo[-1])\n",
    "    state_file.append(index_to_file[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "#-- DEFINING THE TARGET BELL STATE ---\n",
    "######################################\n",
    "\n",
    "# bell=(np.array([1,0,0,0])+np.array([0,0,0,1]))/np.sqrt(2)\n",
    "# bell=(np.array([1,0,0,0])-np.array([0,0,0,1]))/np.sqrt(2)\n",
    "#bell=(np.array([0,1,0,0])+np.array([0,0,1,0]))/np.sqrt(2)\n",
    "# bell=(np.array([0,1,0,0])+np.array([0,0,1,0]))/np.sqrt(2)\n",
    "bell=(np.array([1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0])+np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1]))/np.sqrt(2)\n",
    "bellmatrix=np.array(np.outer(bell, np.conjugate(bell)))\n",
    "\n",
    "# states=state\n",
    "# for index in range(len(states)):\n",
    "#     print(np.real(np.round(states[index].state.fidelity(bell),5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#----- OPTIMIZATION OF MAX FIDELITY UP TO UNITARIES ------\n",
    "##########################################################\n",
    "states=state\n",
    "fid=np.zeros((n_files))\n",
    "optimized_matrix=np.zeros((n_files,2**qubit_number,2**qubit_number), dtype='complex')\n",
    "\n",
    "guess=np.zeros(3*(qubit_number-1))\n",
    "bounds=[(-np.pi,np.pi)]*3*(qubit_number-1)\n",
    "results = []\n",
    "\n",
    "opt=Optimizer(guess, function_fidelity, results=FidelityResults)\n",
    "for index in range(len(states)):\n",
    "    result=opt.optimize(qubit_number,states[index].state, bell, bounds=bounds)\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating new states considering the uncertainties\n",
      "Optimizing the fidelity between input and target up to a unitary\n",
      "file, fidelity, fidelity_mean, fidelity_std:  Simulated\\GHZ (1+0j) 0.99767 0.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "##########################################################\n",
    "#------------ ERRORS Input with BELL STATE---------------#\n",
    "##########################################################\n",
    "error_runs=1\n",
    "\n",
    "U=[]\n",
    "bell_aux=[]\n",
    "target_ini=[]\n",
    "\n",
    "states=state\n",
    "states_file=state_file\n",
    "players=[\"Arya\", \"Bran\",\"Cersei\",\"Dany\"]\n",
    "\n",
    "for index in range(len(states)):\n",
    "    target=bellmatrix\n",
    "    U.append(results[index].u)\n",
    "    target_ini.append(np.transpose(np.conjugate(U[-1]))@bellmatrix@U[-1])    \n",
    "    \n",
    "    states[index].calculate_fidelity_error(players, error_runs, opt, target, optimization=True, bounds=bounds)\n",
    "    \n",
    "    print('file, fidelity, fidelity_mean, fidelity_std: ',\n",
    "          states_file[index], np.round(states[index].state.fidelity(target_ini[-1]),5), -np.round(states[index].fidelity_mu,5),\n",
    "          np.round(states[index].fidelity_std,5), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#--------------- PLOTTING DENSITY MATRIX-----------------#\n",
    "##########################################################\n",
    "results[-1].optimized_state.plot_dm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Everything under this line was used to analyse the quantum transmission certification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#--------------- ERRORS OUTPUT TO INTPUT ----------------#\n",
    "##########################################################\n",
    "U=[]\n",
    "bell_aux=[]\n",
    "target_ini=[]\n",
    "\n",
    "states=state_before\n",
    "\n",
    "for index in range(len(states)):\n",
    "    target=state_after[index]\n",
    "    U.append(np.kron(results[index].u1,results[index].u2))\n",
    "    target_ini.append(np.transpose(np.conjugate(U[-1]))@state_after[index].state.state@U[-1])\n",
    "    \n",
    "    states[index].calculate_fidelity_error_between_2_experimental_matrices(error_runs, players, target, apply_unitary_to_input=True)\n",
    "    \n",
    "    print('file, fidelity, fidelity_mean, fidelity_std: ',\n",
    "          state_after_file[index], np.round(states[index].state.fidelity(target_ini[-1]),5), -np.round(states[index].fidelity_2_experimental_dms_mu,5),\n",
    "          np.round(states[index].fidelity_2_experimental_dms_std,5), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m bell\u001b[38;5;241m=\u001b[39m(np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m]))\u001b[38;5;241m/\u001b[39mnp\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      2\u001b[0m bellmatrix\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray(np\u001b[38;5;241m.\u001b[39mouter(bell, np\u001b[38;5;241m.\u001b[39mconjugate(bell)))\n\u001b[1;32m----> 4\u001b[0m result\u001b[38;5;241m=\u001b[39mopt\u001b[38;5;241m.\u001b[39moptimize(\u001b[43mstate_before\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mstate, bell, bounds\u001b[38;5;241m=\u001b[39mbounds)\n\u001b[0;32m      5\u001b[0m U[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mkron(result\u001b[38;5;241m.\u001b[39mu1,result\u001b[38;5;241m.\u001b[39mu2)\n\u001b[0;32m      7\u001b[0m t\u001b[38;5;241m=\u001b[39mstate_after[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstate\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "bell=(np.array([0,1,0,0])-np.array([0,0,1,0]))/np.sqrt(2)\n",
    "bellmatrix=np.array(np.outer(bell, np.conjugate(bell)))\n",
    "\n",
    "result=opt.optimize(state_before[2].state, bell, bounds=bounds)\n",
    "U[2]=np.kron(result.u1,result.u2)\n",
    "\n",
    "t=state_after[2].state.state\n",
    "\n",
    "t_ini=np.linalg.inv(U[2])@state_after[2].state.state@np.linalg.inv(np.transpose(np.conjugate(U[2])))\n",
    "\n",
    "states[2].calculate_fidelity_error(players, error_runs, opt, t, bounds=bounds)\n",
    "\n",
    "print('index, fidelity, fidelity_mean, fidelity_std: ',\n",
    "        state_before_file[index], np.round(states[2].state.fidelity(t_ini),5), np.round(states[2].fidelity_mu,5),\n",
    "        np.round(states[2].fidelity_std,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#------------ ERRORS OUTPUT with BELL STATE--------------#\n",
    "##########################################################\n",
    "bell=(np.array([0,1,0,0])+np.array([0,0,1,0]))/np.sqrt(2)\n",
    "bellmatrix=np.array(np.outer(bell, np.conjugate(bell)))\n",
    "error_runs=30\n",
    "\n",
    "U=[]\n",
    "bell_aux=[]\n",
    "target_ini=[]\n",
    "\n",
    "states=state_after\n",
    "players=[\"Arya\", \"Cersei\"]\n",
    "\n",
    "guess=np.array([0, 0, 0])\n",
    "bounds=[(-np.pi,np.pi)]*3\n",
    "opt=Optimizer(guess, function_fidelity, results=FidelityResults)\n",
    "\n",
    "for index in range(len(states)):\n",
    "    target=bellmatrix\n",
    "    #U.append(results[index].u)\n",
    "    #target_ini.append(np.transpose(np.conjugate(U[-1]))@bellmatrix@U[-1])    \n",
    "    \n",
    "    states[index].calculate_fidelity_error(players, error_runs, opt, target, bounds=bounds)\n",
    "    \n",
    "    print('index, fidelity, fidelity_mean, fidelity_std: ',\n",
    "          state_after_file[index], np.round(states[index].state.fidelity(target),5), np.round(states[index].fidelity_mu,5),\n",
    "          np.round(states[index].fidelity_std,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bell=(np.array([0,1,0,0])-np.array([0,0,1,0]))/np.sqrt(2)\n",
    "bellmatrix=np.array(np.outer(bell, np.conjugate(bell)))\n",
    "target=bellmatrix\n",
    "\n",
    "result=opt.optimize(state_before[2].state, bell, bounds=bounds)\n",
    "\n",
    "t=state_after[2].state.state\n",
    "\n",
    "states[2].calculate_fidelity_error(players, error_runs, opt, t, bounds=bounds)\n",
    "\n",
    "print('index, fidelity, fidelity_mean, fidelity_std: ',\n",
    "        state_after_file[index], np.round(states[2].state.fidelity(target),5), np.round(states[2].fidelity_mu,5),\n",
    "        np.round(states[2].fidelity_std,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#------------ WRITING THE DATA IN AN EXCEL ---------------\n",
    "##########################################################\n",
    "\n",
    "import xlsxwriter\n",
    "states=state_before\n",
    "\n",
    "workbook = xlsxwriter.Workbook('fidelities_to_ini_state_errors.xlsx') ### We should write this in another place\n",
    " \n",
    "worksheet = workbook.add_worksheet()\n",
    "\n",
    "worksheet.write('A1', 'Number')\n",
    "worksheet.write('B1', 'Folder')\n",
    "worksheet.write('C1', 'Fidelity')\n",
    "worksheet.write('D1', 'Fidelity_mean')\n",
    "worksheet.write('E1', 'Fidelity_uncertainty')\n",
    "\n",
    "counter=0\n",
    "for index in range(len(state_before)):\n",
    "    \n",
    "    worksheet.write('A'+str(counter+2), counter)\n",
    "    worksheet.write('B'+str(counter+2), state_before_file[index])\n",
    "    worksheet.write('C'+str(counter+2), np.real(np.round(states_final[index].fidelity(target[index]),5)))#np.round(states[index].fidelity_to_pure(bell),5)))\n",
    "    worksheet.write('D'+str(counter+2), np.real(np.round(states_final[index].mu,5)))\n",
    "    worksheet.write('E'+str(counter+2), np.real(np.round(states_final[index].std,5)))\n",
    "    counter+=1\n",
    "        \n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GHZ_state' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mGHZ_state\u001b[49m[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mGHZ_state)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'GHZ_state' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IF WE WANT TO CHECK THE FIT TO THE UNCERTARTAINTY\n",
    "### Then we need to calculate the statistic on these simulated fidelities and calculate the standart deviation\n",
    "### This will be our uncertainty due to statistical errors\n",
    "def count_elements(seq) -> dict:\n",
    "    hist = {}\n",
    "    for i in seq:\n",
    "        hist[i] = hist.get(i, 0) + 1\n",
    "    return hist\n",
    "\n",
    "counted = count_elements(fidelity_sim)\n",
    "#print(counted)\n",
    "bin_numb = len(counted)\n",
    "errorbar_x=np.array(list(counted))\n",
    "errorbar_y=np.zeros((bin_numb), dtype=int)\n",
    "\n",
    "for i in range(bin_numb):\n",
    "    errorbar_y[i]=counted[errorbar_x[i]]\n",
    "    \n",
    "#print(errorbar_x)\n",
    "#print(errorbar_y)\n",
    "    \n",
    "def Gauss(x, A, mu, sigm):\n",
    "    y = A*np.exp(-((x-mu)/sigm)**2/2)\n",
    "    return y\n",
    "\n",
    "mu, std = norm.fit(fidelity_sim)\n",
    "print(mu, std)\n",
    "parameters, covariance = curve_fit(Gauss, xdata=errorbar_x[-1], ydata=errorbar_y[:-1], bounds=[(0,0.99007,1e-4),(60,0.9903,0.0002)])\n",
    "fit_A = parameters[0]\n",
    "fit_B = parameters[1]\n",
    "fit_C = parameters[2]\n",
    "print(fit_A, fit_B, fit_C)\n",
    "\n",
    "xdata= x = np.linspace(0.989, 0.991, 100)\n",
    "fit_y = Gauss(xdata, fit_A, fit_B, fit_C)\n",
    "plt.plot(errorbar_x[:-1], errorbar_y[:-1], 'o', label='data')\n",
    "plt.plot(xdata, fit_y, '-', label='fit')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This was to analyse the quantum channel certification paper\n",
    "# state_after=[]\n",
    "# state_after_file=[]\n",
    "\n",
    "# state_before=[]\n",
    "# state_before_file=[]\n",
    "\n",
    "## The 'e' and 'r' serve to distinguish between tomography before and after, respectively\n",
    "    ## We want to save them in different arrays because we need them for different things\n",
    "#     elif index_to_file[index][-8]=='e':\n",
    "#         state_before.append(statetomo[-1])#.state)\n",
    "#         state_before_file.append(index_to_file[index])\n",
    "#         #print('\\n Fast maximum likelihood estimation: \\n', state_before[-1], '\\n')\n",
    "\n",
    "#     elif index_to_file[index][-8]=='r':\n",
    "#         state_after.append(statetomo[-1])#.state)\n",
    "#         state_after_file.append(index_to_file[index])\n",
    "#         #print('\\n Fast maximum likelihood estimation: \\n', state_after[-1], '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
