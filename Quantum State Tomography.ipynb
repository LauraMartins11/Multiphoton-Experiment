{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import time\n",
    "import math\n",
    "from scipy.stats import norm\n",
    "\n",
    "import mystic\n",
    "from mystic.solvers import DifferentialEvolutionSolver, diffev2\n",
    "from mystic.strategy import Best1Bin\n",
    "from mystic.monitors import Monitor,VerboseMonitor\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from tomography import *\n",
    "\n",
    "from NestedForLoop import get_iterator\n",
    "from pathlib import Path\n",
    "from scipy.linalg import sqrtm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.optimize import least_squares\n",
    "\n",
    "import fnmatch\n",
    "from efficiencies import finding_file, get_channels_eff, set_raw_counts\n",
    "from optimization import Optimizer, function_fidelity, FidelityResults\n",
    "from constants import *\n",
    "\n",
    "from densitymatrix import DensityMatrix, apply_unitary_to_dm\n",
    "\n",
    "from pathlib import Path\n",
    "import fnmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = os.getcwd()\n",
    "working_dir_data = os.getcwd()+'\\StateTomoData'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "######################################################################################################\n",
    "#----- COUNTING THE FILES AND SAVING THEM IN AN ARRAY TO MAKES THE REST OF THE ANALYSIS EASIER -------\n",
    "######################################################################################################\n",
    "\n",
    "n_files=0\n",
    "working_dir=r\"C:\\Users\\nicol\\Desktop\\Experiment\"\n",
    "os.chdir(working_dir)\n",
    "\n",
    "filenames = [i for i in glob.glob(\"StateTomography_2Layers_*\")]\n",
    "filenames.sort(key=os.path.getmtime)\n",
    "\n",
    "index_to_file = {}\n",
    "\n",
    "for index, filename in enumerate(filenames):\n",
    "    os.chdir(f\"{working_dir}\\\\{filename}\")\n",
    "    filenames_aux=[i for i in glob.glob(\"StateTomo_2Layers*\")]\n",
    "    for index_second, filenames_aux_second in enumerate(filenames_aux):\n",
    "        index_to_file[n_files] = f\"{filename}\\\\{filenames_aux_second}\"\n",
    "        n_files+=1\n",
    "os.chdir(working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(working_dir)\n",
    "qubit_number=2\n",
    "\n",
    "## Defining the columns of the data file we want to use as data to reconstruct the density matrix (eg.: HH HV VH and VV basis)\n",
    "column_start=8\n",
    "column_stop=12\n",
    "\n",
    "column_start_2_emissions=16\n",
    "column_stop_2_emissions=20\n",
    "\n",
    "state_after=[]\n",
    "state_after_file=[]\n",
    "\n",
    "state_before=[]\n",
    "state_before_file=[]\n",
    "\n",
    "state = []\n",
    "state_file=[]\n",
    "\n",
    "xp_counts_corrected_with_eff=[]\n",
    "\n",
    "statetomo = []\n",
    "\n",
    "#####################################################################\n",
    "#---------------------- STATE TOMOGRAPHY ----------------------------\n",
    "#####################################################################\n",
    "for index in range(len(index_to_file)):\n",
    "    os.chdir(f\"{working_dir}\\\\{index_to_file[index]}\\\\\")\n",
    "    datafiles=[i for i in glob.glob(\"*\")]\n",
    "                \n",
    "    ### Calculating the efficiencies of each detector\n",
    "    efficiencies=get_channels_eff(datafiles, column_start, column_stop, os.getcwd())\n",
    "    efficiencies_2_emissions=get_channels_eff(datafiles, column_start_2_emissions, column_stop_2_emissions, os.getcwd())\n",
    "\n",
    "\n",
    "    ### Opening the data files and writing the data in counts_aux array\n",
    "    counts_aux=set_raw_counts(datafiles, qubit_number, column_start, column_stop, os.getcwd())\n",
    "    xp_counts=np.array(np.transpose(counts_aux))\n",
    " \n",
    "    counts_aux_2_emissions=set_raw_counts(datafiles, qubit_number, column_start_2_emissions, column_stop_2_emissions, os.getcwd())\n",
    "    xp_counts_2_emissions=np.array(np.transpose(counts_aux_2_emissions))\n",
    "\n",
    "    statetomo.append(LRETomography(int(qubit_number),xp_counts, xp_counts_2_emissions))\n",
    "    statetomo[-1].run(correct_eff=efficiencies,correct_double_emission_eff=efficiencies_2_emissions)\n",
    "#     statetomo[-1].run(print_nc=False)\n",
    "    xp_counts_corrected_with_eff.append(statetomo[-1].xp_counts)\n",
    "\n",
    "    ## The 'e' and 'r' serve to distinguish between tomography before and after, respectively\n",
    "    ## We want to save them in different arrays because we need them for different things\n",
    "#     elif index_to_file[index][-8]=='e':\n",
    "#         state_before.append(statetomo[-1])#.state)\n",
    "#         state_before_file.append(index_to_file[index])\n",
    "#         #print('\\n Fast maximum likelihood estimation: \\n', state_before[-1], '\\n')\n",
    "\n",
    "#     elif index_to_file[index][-8]=='r':\n",
    "#         state_after.append(statetomo[-1])#.state)\n",
    "#         state_after_file.append(index_to_file[index])\n",
    "#         #print('\\n Fast maximum likelihood estimation: \\n', state_after[-1], '\\n')\n",
    "        \n",
    "    state.append(statetomo[-1])#.state)\n",
    "    state_file.append(index_to_file[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# states=state\n",
    "# for index in range(len(states)):\n",
    "#     print(np.real(np.round(states[index].state.fidelity(bell),5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "#-- DEFINING THE TARGET BELL STATE ---\n",
    "######################################\n",
    "\n",
    "# bell=(np.array([1,0,0,0])+np.array([0,0,0,1]))/np.sqrt(2)\n",
    "# bell=(np.array([1,0,0,0])-np.array([0,0,0,1]))/np.sqrt(2)\n",
    "bell=(np.array([1,0,0,0])+np.array([0,0,0,1]))/np.sqrt(2)\n",
    "# bell=(np.array([0,1,0,0])-np.array([0,0,1,0]))/np.sqrt(2)\n",
    "bellmatrix=np.array(np.outer(bell, np.conjugate(bell)))\n",
    "\n",
    "##########################################################\n",
    "#----- OPTIMIZATION OF MAX FIDELITY UP TO UNITARIES ------\n",
    "##########################################################\n",
    "states=state\n",
    "fid=np.zeros((n_files))\n",
    "optimized_matrix=np.zeros((n_files,2**qubit_number,2**qubit_number), dtype='complex')\n",
    "\n",
    "guess=np.array([0, 0, 0])\n",
    "bounds=[(-np.pi,np.pi)]*3\n",
    "results = []\n",
    "\n",
    "opt=Optimizer(guess, function_fidelity, results=FidelityResults)\n",
    "\n",
    "for index in range(len(states)):\n",
    "    result=opt.optimize(states[index].state, bell, bounds=bounds)\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating new states considering the uncertainties\n",
      "Optimizing the fidelity between input and target up to a unitary\n",
      "file, fidelity, fidelity_mean, fidelity_std:  StateTomography_2Layers_20230330\\StateTomo_2Layers (0.97468+0j) 0.97437 0.00042 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "##########################################################\n",
    "#------------ ERRORS Input with BELL STATE---------------#\n",
    "##########################################################\n",
    "error_runs=10\n",
    "\n",
    "U=[]\n",
    "bell_aux=[]\n",
    "target_ini=[]\n",
    "\n",
    "states=state\n",
    "states_file=state_file\n",
    "players=[\"Cersei\", \"Dany\"]\n",
    "\n",
    "for index in range(len(states)):\n",
    "    target=bellmatrix\n",
    "    U.append(results[index].u)\n",
    "    target_ini.append(np.transpose(np.conjugate(U[-1]))@bellmatrix@U[-1])    \n",
    "    \n",
    "    states[index].calculate_fidelity_error(players, error_runs, opt, target, optimization=True, bounds=bounds)\n",
    "    \n",
    "    print('file, fidelity, fidelity_mean, fidelity_std: ',\n",
    "          states_file[index], np.round(states[index].state.fidelity(target_ini[-1]),5), -np.round(states[index].fidelity_mu,5),\n",
    "          np.round(states[index].fidelity_std,5), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#--------------- ERRORS OUTPUT TO INTPUT ----------------#\n",
    "##########################################################\n",
    "U=[]\n",
    "bell_aux=[]\n",
    "target_ini=[]\n",
    "\n",
    "states=state_before\n",
    "\n",
    "for index in range(len(states)):\n",
    "    target=state_after[index]\n",
    "    U.append(np.kron(results[index].u1,results[index].u2))\n",
    "    target_ini.append(np.transpose(np.conjugate(U[-1]))@state_after[index].state.state@U[-1])\n",
    "    \n",
    "    states[index].calculate_fidelity_error_between_2_experimental_matrices(error_runs, players, target, apply_unitary_to_input=True)\n",
    "    \n",
    "    print('file, fidelity, fidelity_mean, fidelity_std: ',\n",
    "          state_after_file[index], np.round(states[index].state.fidelity(target_ini[-1]),5), -np.round(states[index].fidelity_2_experimental_dms_mu,5),\n",
    "          np.round(states[index].fidelity_2_experimental_dms_std,5), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bell=(np.array([0,1,0,0])-np.array([0,0,1,0]))/np.sqrt(2)\n",
    "bellmatrix=np.array(np.outer(bell, np.conjugate(bell)))\n",
    "\n",
    "result=opt.optimize(state_before[2].state, bell, bounds=bounds)\n",
    "U[2]=np.kron(result.u1,result.u2)\n",
    "\n",
    "t=state_after[2].state.state\n",
    "\n",
    "t_ini=np.linalg.inv(U[2])@state_after[2].state.state@np.linalg.inv(np.transpose(np.conjugate(U[2])))\n",
    "\n",
    "states[2].calculate_fidelity_error(players, error_runs, opt, t, bounds=bounds)\n",
    "\n",
    "print('index, fidelity, fidelity_mean, fidelity_std: ',\n",
    "        state_before_file[index], np.round(states[2].state.fidelity(t_ini),5), np.round(states[2].fidelity_mu,5),\n",
    "        np.round(states[2].fidelity_std,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#------------ ERRORS OUTPUT with BELL STATE--------------#\n",
    "##########################################################\n",
    "bell=(np.array([0,1,0,0])+np.array([0,0,1,0]))/np.sqrt(2)\n",
    "bellmatrix=np.array(np.outer(bell, np.conjugate(bell)))\n",
    "error_runs=30\n",
    "\n",
    "U=[]\n",
    "bell_aux=[]\n",
    "target_ini=[]\n",
    "\n",
    "states=state_after\n",
    "players=[\"Arya\", \"Cersei\"]\n",
    "\n",
    "guess=np.array([0, 0, 0])\n",
    "bounds=[(-np.pi,np.pi)]*3\n",
    "opt=Optimizer(guess, function_fidelity, results=FidelityResults)\n",
    "\n",
    "for index in range(len(states)):\n",
    "    target=bellmatrix\n",
    "    #U.append(results[index].u)\n",
    "    #target_ini.append(np.transpose(np.conjugate(U[-1]))@bellmatrix@U[-1])    \n",
    "    \n",
    "    states[index].calculate_fidelity_error(players, error_runs, opt, target, bounds=bounds)\n",
    "    \n",
    "    print('index, fidelity, fidelity_mean, fidelity_std: ',\n",
    "          state_after_file[index], np.round(states[index].state.fidelity(target),5), np.round(states[index].fidelity_mu,5),\n",
    "          np.round(states[index].fidelity_std,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bell=(np.array([0,1,0,0])-np.array([0,0,1,0]))/np.sqrt(2)\n",
    "bellmatrix=np.array(np.outer(bell, np.conjugate(bell)))\n",
    "target=bellmatrix\n",
    "\n",
    "result=opt.optimize(state_before[2].state, bell, bounds=bounds)\n",
    "\n",
    "t=state_after[2].state.state\n",
    "\n",
    "states[2].calculate_fidelity_error(players, error_runs, opt, t, bounds=bounds)\n",
    "\n",
    "print('index, fidelity, fidelity_mean, fidelity_std: ',\n",
    "        state_after_file[index], np.round(states[2].state.fidelity(target),5), np.round(states[2].fidelity_mu,5),\n",
    "        np.round(states[2].fidelity_std,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#------------ WRITING THE DATA IN AN EXCEL ---------------\n",
    "##########################################################\n",
    "\n",
    "import xlsxwriter\n",
    "states=state_before\n",
    "\n",
    "workbook = xlsxwriter.Workbook('fidelities_to_ini_state_errors.xlsx') ### We should write this in another place\n",
    " \n",
    "worksheet = workbook.add_worksheet()\n",
    "\n",
    "worksheet.write('A1', 'Number')\n",
    "worksheet.write('B1', 'Folder')\n",
    "worksheet.write('C1', 'Fidelity')\n",
    "worksheet.write('D1', 'Fidelity_mean')\n",
    "worksheet.write('E1', 'Fidelity_uncertainty')\n",
    "\n",
    "counter=0\n",
    "for index in range(len(state_before)):\n",
    "    \n",
    "    worksheet.write('A'+str(counter+2), counter)\n",
    "    worksheet.write('B'+str(counter+2), state_before_file[index])\n",
    "    worksheet.write('C'+str(counter+2), np.real(np.round(states_final[index].fidelity(target[index]),5)))#np.round(states[index].fidelity_to_pure(bell),5)))\n",
    "    worksheet.write('D'+str(counter+2), np.real(np.round(states_final[index].mu,5)))\n",
    "    worksheet.write('E'+str(counter+2), np.real(np.round(states_final[index].std,5)))\n",
    "    counter+=1\n",
    "        \n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IF WE WANT TO CHECK THE FIT TO THE UNCERTARTAINTY\n",
    "### Then we need to calculate the statistic on these simulated fidelities and calculate the standart deviation\n",
    "### This will be our uncertainty due to statistical errors\n",
    "def count_elements(seq) -> dict:\n",
    "    hist = {}\n",
    "    for i in seq:\n",
    "        hist[i] = hist.get(i, 0) + 1\n",
    "    return hist\n",
    "\n",
    "counted = count_elements(fidelity_sim)\n",
    "#print(counted)\n",
    "bin_numb = len(counted)\n",
    "errorbar_x=np.array(list(counted))\n",
    "errorbar_y=np.zeros((bin_numb), dtype=int)\n",
    "\n",
    "for i in range(bin_numb):\n",
    "    errorbar_y[i]=counted[errorbar_x[i]]\n",
    "    \n",
    "#print(errorbar_x)\n",
    "#print(errorbar_y)\n",
    "    \n",
    "def Gauss(x, A, mu, sigm):\n",
    "    y = A*np.exp(-((x-mu)/sigm)**2/2)\n",
    "    return y\n",
    "\n",
    "mu, std = norm.fit(fidelity_sim)\n",
    "print(mu, std)\n",
    "parameters, covariance = curve_fit(Gauss, xdata=errorbar_x[-1], ydata=errorbar_y[:-1], bounds=[(0,0.99007,1e-4),(60,0.9903,0.0002)])\n",
    "fit_A = parameters[0]\n",
    "fit_B = parameters[1]\n",
    "fit_C = parameters[2]\n",
    "print(fit_A, fit_B, fit_C)\n",
    "\n",
    "xdata= x = np.linspace(0.989, 0.991, 100)\n",
    "fit_y = Gauss(xdata, fit_A, fit_B, fit_C)\n",
    "plt.plot(errorbar_x[:-1], errorbar_y[:-1], 'o', label='data')\n",
    "plt.plot(xdata, fit_y, '-', label='fit')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
